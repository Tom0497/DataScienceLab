{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MA6202: Laboratorio de Ciencia de Datos\n",
    "\n",
    "**Profesor: Nicolás Caro**\n",
    "\n",
    "**27/05/2020 - C10 S6**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computación de alto Rendimiento con Python\n",
    "\n",
    "Python es utilizado transversalmente, ya sea en la industria o en la academia. Dentro de sus cualidades se encuentra la portabilidad de código, sintaxis intuitiva, disponibilidad de herramientas y documentación. Sin embargo, al ser un lenguaje interpretado se pierden ciertas características intrínsicas de los lenguajes de bajo nivel como C, C++ y Fortran.\n",
    "\n",
    "Se estudian distintas herramientas para mejorar el rendimiento del interprete CPython, estas se basan en el uso eficiente de objetos base, aplicación de técnicas de paralelismo y compilación utilizando tanto librerías nativas, como desarrolladas por terceros. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perfilamiento y Referenciación\n",
    "\n",
    "El flujo de trabajo en ciencia de datos consta de numerosas rutinas de carga, procesamiento, visualización y optimización. Estas rutinas son abordadas por medio de técnicas de programación y diseño de código. En este apartado, se debe tener en cuenta la importancia de generar rutinas eficientes, pues significan reducciones en los tiempos de respuesta y uso de recursos. Por lo anterior, es natural que desde fases tempranas del desarrollo de proyectos, se busque optimizar el código. Como directriz general, se recomienda llevar el proceso de desarrollo en dos etapas. La primera consiste en generar rutinas **correctas**, **comprensibles** y **mantenibles**, evitando la sobre-optimización prematura de código. Como segunda etapa, se recomienda comenzar con los procesos de optimización de rutinas. Esto pues, las herramientas que permiten mejorar los aspectos computacionales, interfieren en la sencillez del código, entorpeciendo los procesos de depuración y mantención. \n",
    "\n",
    "Una vez que las rutinas están implementadas de manera correcta, la mejor manera de enfocar los esfuerzos, pasa por **perfilar** (*profiling*) las rutinas codificadas. Esto consiste en encontrar las zonas de código criticas en cuanto a carga computacional. La manera más directa de encontrar estas zonas, es por medio del uso de contadores de tiempo o *timers*.\n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "Se utiliza la librería `time` para medir el tiempo de ejecución de una zona de código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sin, cos\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se define la función a analizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_1(a):\n",
    "    \n",
    "    result = 0\n",
    "    for val in a:\n",
    "        result += sin(val) + cos(val)**2\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se define un rango de datos a operar y se estudia el tiempo de ejecución por medio de la función `process_time`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [0.1 * i for i in range(1000)]\n",
    "\n",
    "t0 = time.process_time()\n",
    "for r in range(1000):\n",
    "    func_1(x)\n",
    "t1 = time.process_time()\n",
    "\n",
    "\n",
    "print(\"Tiempo transcurrido\", t1 - t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio**\n",
    "\n",
    "1. Defina una clase *context manager* llamada `Timer`. Esta debe abstraer la dinámica de medición temporal anterior. *Hint*: Deberá definir los métodos `__enter__` y `__exit__`, en este último se produce el `print` de tiempo transcurrido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En algunas ocasiones se desea medir el tiempo de ejecución para tareas sencillas, la librería estándar de Python provee el módulo `timeit`, este puede ser utilizado directamente en la consola interactiva IPython o en notebooks de Jupyter por medio del comando mágico `%timeit`. \n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "Se mide el tiempo de ejecución promedio para la función coseno de NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit np.cos(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se compara con la función del módulo `Math`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit cos(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede ver una gran diferencia en los tiempos de ejecución promedio. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio**\n",
    "\n",
    "1. Diferencie los comandos `%time`, `%timeit`, `%%timeit`.\n",
    "2. En Pyhton existen 2 maneras para declarar listas, tuplas y diccionarios, una de ellas es la *forma funcional* y viene dada por la función de conversión de tipo de datos, por ejemplo para diccionarios es `dict()`. La otra forma es utilizar *expresiones literales* esto quiere decir declarar listas usando `[]`, tuplas usando `()` y diccionarios / conjuntos usando `{}`. Una de estas dos maneras es más rápida que la otra, utilice `%timeit` para deducir cual. \n",
    "3. ¿Qué operación es más eficiente ?\n",
    "\n",
    "    1. `list(range())`\n",
    "    2. `[*range()]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un **perfilador**  (*profiler*) es un programa que ejecuta una rutina y monitorea las funciones ahí especificadas, obteniendo métricas de rendimiento como el consumo de tiempo y memoria. Por otra parte, la referenciación (*benchmarking*) consiste en extraer zonas de código de interés para probar su rendimiento antes y después de aplicar técnicas de optimización. IPython provee de un perfilador de código dado por la orden `%prun`.\n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "1. Se perfila una función utilizando `%prun`. En primera instancia se define tal función"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_sum(n):\n",
    "    '''Funcion de referencia que suma n elementos transformados\n",
    "    '''\n",
    "    ac = 0\n",
    "    \n",
    "    for i in range(n):\n",
    "        to_sum = [(i // 2)**n + (i-n)**(n // 3) for i in range(n)]\n",
    "        ac = sum(to_sum)\n",
    "    \n",
    "    return ac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se perfila la función con `%prun`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%prun benchmark_sum(500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EL resultado corresponde las mediciones temporales de cada función involucrada en la ejecución de `benchmark_sum(500)`. En este caso, la mayoria del tiempo se utiliza en la ejecución de la compresión de listas `<listcomp>`. Esto indica que la mejor manera de optimizar el código de `benchmark_sum`pasa por optimizar tal sección del código."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con `%lprun` es posible perfilar por linea de código, para ello es necesario instalar el módulo `line_profiler`. \n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "Se carga la extensión `%lprun` y se prueba con `benchmark_sum`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El comando `%lprun` toma como parámetro una orden de Python y su principal argumento. Las funciones que se desean perfilar deben ser especificadas de manera explicita con la orden `-f`. En el caso de `benchmark_sum` esto se haría según el siguiente código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -f benchmark_sum benchmark_sum(500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultado es una tabla con el tiempo utilizado en cada linea de las funciones perfiladas, mostrando porcentajes del tiempo consumido en cada paso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio**\n",
    "\n",
    "1. Los perfiladores `%prun` y `%lprun` tienen en común los argumentos -D, -T y -r utilice el parámetro `?` para investigar estas opciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es posible perfilar uso de memoria, para ello existen los comandos mágicos `%memit` y `%mprun`. Para utilizarlos es necesario instalar el módulo `memory_profiler` y cargarlo mediante\n",
    "\n",
    "```python\n",
    "%load_ext memory_profiler\n",
    "```\n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "Se carga la extensión y se perfila el uso de memoria para `benchmark_sum`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primera instancia perfilamos utilizando la linea mágica `%memit`, la cual es equivalente a `timeit` pero ofrece medidas sobre el uso de memoria. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%memit benchmark_sum(500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede observar un uso de memoria en torno a 90 MB.\n",
    "\n",
    "De manera análoga a `%prun` la librería `memory_profiler` permite utilizar `%mprun`, con la cual se pueden obtener descripciones linea a linea del uso de memoria. El uso de este comando es un poco más restrictivo, pues solo permite medir funciones definidas en módulos (no dentro de un notebook). Para ello, se crea el módulo `memory_demo`. La manera sencilla de hacer esto, es mediante el comando mágico `%%file` este permite crear archivos en el directorio de trabajo actual, utilizando el código dentro de una celda de jupyter. \n",
    "\n",
    "Se procede a generar el módulo que contiene el código de `benchmark_sum` utilizando el comando `%%file`.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file bench_module.py\n",
    "\n",
    "def benchmark_sum(n):\n",
    "    '''Funcion de referencia que suma n elementos transformados\n",
    "    '''\n",
    "    ac = 0\n",
    "    \n",
    "    for i in range(n):\n",
    "        to_sum = [(i // 2)**n + (i-n)**(n // 3) for i in range(n)]\n",
    "        ac = sum(to_sum)\n",
    "    \n",
    "    return ac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a continuación, se importa el módulo creado y se perfuila su memoria mediante:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bench_module import benchmark_sum\n",
    "%mprun -f benchmark_sum benchmark_sum(500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultado se muestra en pantalla, obteniendo detalles linea a linea."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio**\n",
    "\n",
    "1. Agregue la linea `del to_sum` luego de ejecutar `ac = sum(to_sum)` y antes de terminar el ciclo `for` principal. Estudie el efecto en el consumo de memoria en la función."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimización con Código Nativo\n",
    "\n",
    "Una de las manera más eficientes de mejorar el rendimiento de aplicaciones es por medio del uso de algoritmos más eficientes en conjunción de estructuras de datos mejor diseñadas. A continuación, se estudian los algoritmos y estructuras de datos presentes de manera nativa en Python que permiten acelerar ciertas rutinas. \n",
    "\n",
    "En términos generales, lso algoritmos pueden ser clasificados según su *complejidad computacional*, esta clasificación se expresa según la notación de O-grande, que corresponde a una cota superior de las operaciones requeridas para ejecutar una tarea.\n",
    "\n",
    "Si la tarea no depende del tamaño del input (acceder a cierta llave de un diccionario por ejemplo) se dice que el algoritmo asociado se efectúa en tiempo constante, denotado por $O(1)$. Esto quiere decir, que sin importar la cantidad de datos disponibles, el tiempo de ejecución de la tarea será siempre el mismo. \n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "Se genera un lista, a cada uno de sus elementos se le realiza una operación básica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista = list(range(10))\n",
    "\n",
    "for i in range(len(lista)):\n",
    "    lista[i]+=100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este algoritmo, la operación `lista[i]+=100` es repetida tantas veces como elementos hay en `lista`, que corresponde al tamaño de los datos de entrada. Al observar la que las operaciones realizadas por este algoritmo son proporcionales a la cantidad de elementos de `lista`, se puede decir que su tiempo de ejecución es $O(N)$ donde `N = len(lista)`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimización de Operaciones con Listas\n",
    "\n",
    "Las listas de Python son colecciones ordenadas de elementos, estás se encuentran clasificadas como *arreglos*, que a la vez corresponden a una estructura de datos caracterizada por contener elementos contiguos en bloques de memoria, cada uno de los cuales contienen una referencia a un objeto de Python. La ventaja de las listas recae en la facilidad que entregan par acceder, modificar y agregar elementos. Dado que acceder y modificar elementos de una lista corresponde a acceder a espacios de memoria que a priori no dependen de la longitud de la lista, se dice que estas operaciones tienen complejidad $O(1)$. Por otra parte, para agregar un elemento a una lista por medio de `.append()`, puede requerirse re-ubicar la memoria del arreglo asociado, operación que toma un tiempo de $O(N)$. Sin embargo, tal operación es muy poco frecuente, pues por lo general se tiene acceso a bloques de memoria contiguos, por tal motivo, se dice que la operación `.append()` tiene un tiempo esperado de ejecución de $O(1)$. \n",
    "\n",
    "Para agregar o eliminar datos al inicio de un arreglo, se requiere hacer una traslación (o *shift*) de los demás elementos por lo que tal operación toma un tiempo de $O(N)$. Para agregar o remover elementos de un arreglo en una posición distinta a la última, se opera de manera análoga. \n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "Se definen listas para estudiar la complejidad de ciertos métodos empíricamente. Se definen los parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_0, n_1, n_2 = (int(10e5), int(5*10e5), int(10e6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se generan una funciones de referencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_objs(obj_0,obj_1,obj_2):\n",
    "    '''Abstraccion auxiliar para copiar elementos.'''\n",
    "    return (obj_0.copy(),obj_1.copy(),obj_2.copy())\n",
    "\n",
    "def bench_pop(l_0,l_1,l_2, index = -1):\n",
    "    '''Funcion de referncia para eliminacion de elementos.'''\n",
    "    \n",
    "    l_0.pop(index)\n",
    "    l_1.pop(index)\n",
    "    l_2.pop(index)\n",
    "    \n",
    "\n",
    "def bench_append(l_0,l_1,l_2, index = 1):\n",
    "    '''Funcion de referencia para insertar 1 con append.'''\n",
    "    \n",
    "    l_0.append(index)\n",
    "    l_1.append(index)\n",
    "    l_2.append(index)\n",
    "    \n",
    "\n",
    "def bench_insert(l_0,l_1,l_2, index = (0,1)):\n",
    "    '''Funcion de referncia para insertar 1 con insert.'''\n",
    "    \n",
    "    l_0.insert(*index)\n",
    "    l_1.insert(*index)\n",
    "    l_2.insert(*index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se construye el test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_0, lista_1, lista_2 = (list(range(n_0)), list(range(n_1)),\n",
    "                             list(range(n_2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se elimina el ultimo elemento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_0,l_1,l_2 = copy_objs(lista_0, lista_1, lista_2)\n",
    "\n",
    "# Se observa un tiempo constante\n",
    "%lprun -f bench_pop bench_pop(l_0,l_1,l_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se elimina el primer elemento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se elimina el primer elemento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_0,l_1,l_2 = copy_objs(lista_0, lista_1, lista_2)\n",
    "\n",
    "# Se observa un tiempo lineal\n",
    "%lprun -f bench_pop bench_pop(l_0,l_1,l_2,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se inserta 1 en la ultima posicion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_0,l_1,l_2 = copy_objs(lista_0, lista_1, lista_2)\n",
    "\n",
    "# Se observa un tiempo constante (casi seguramente)\n",
    "%lprun -f  bench_append bench_append(l_0,l_1,l_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se inserta 1 en la primera posicion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_0,l_1,l_2 = copy_objs(lista_0, lista_1, lista_2)\n",
    "\n",
    "# Se observa un tiempo lineal\n",
    "%lprun -f bench_insert bench_insert(l_0,l_1,l_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para efectuar inserciones de manera eficiente (siempre en tiempo constante) Se puede utilizar la estructura de datos `deque` del módulo `collections`. Estas estructuras se comportan como listas, están diseñadas para acelerar la inserción de objetos y añaden los métodos `.popleft` y `.appendleft`. \n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "Se compara `.popleft` en *deques* con `.pop(0)` en listas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "def bench_pop_left(d_0,d_1,d_2):\n",
    "    '''Funcion de referncia para eliminacion de elementos.'''\n",
    "    \n",
    "    d_0.popleft()\n",
    "    d_1.popleft()\n",
    "    d_2.popleft()\n",
    "    \n",
    "def bench_append_left(d_0,d_1,d_2, val = 1):\n",
    "    '''Funcion de referncia para insertar 1 con insert.'''\n",
    "\n",
    "    d_0.appendleft(val)\n",
    "    d_1.appendleft(val)\n",
    "    d_2.appendleft(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se definen los objetos sobre los que se trabajará"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deque_0, deque_1, deque_2 = tuple(map(deque, [lista_1, lista_1, lista_2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_0, d_1, d_2 = copy_objs(deque_0,deque_1,deque_2)\n",
    "\n",
    "# Se observa un tiempo constante\n",
    "%lprun -f bench_pop_left bench_pop_left(d_0, d_1, d_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit \n",
    "d_0, d_1, d_2 = copy_objs(deque_0,deque_1,deque_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copiar objetos de tipo `deque` tiene una carga de aproximadamente 190 ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit \n",
    "d_0, d_1, d_2 = copy_objs(deque_0,deque_1,deque_2)\n",
    "bench_pop_left(d_0, d_1, d_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por su parte, aplicar el benchmark `bench_pop_left` tarda en promedio 191 - 190 ms = 1 ms.\n",
    "\n",
    "En cuanto a las listas, la operación de copiar lleva unos 112 ms en promedio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit \n",
    "l_0,l_1,l_2 = copy_objs(lista_0, lista_1, lista_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicar el benchmark `bench_pop` en listas lleva un tiempo promedio de 120 ms - 112 ms = 8ms. Por lo que se aprecia un aumento en el rendimiento. Cabe señalar que tal aumento se ve sujeto a una carga mayor en el proceso de copia de objetos, por tal motivo, vale la pena evitar la copia de objetos tipo `deque` y utilizarlos para acceder a lista con una gran cantidad de elementos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit \n",
    "l_0,l_1,l_2 = copy_objs(lista_0, lista_1, lista_2)\n",
    "bench_pop(lista_0,lista_1,lista_2,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicios**\n",
    "\n",
    "1. Repita el proceso de comparación para `.appendleft` en deques  e `.insert()` en listas. \n",
    "\n",
    "2. Cual es la complejidad computacional de acceder a:\n",
    "    1. Primer elemento de un deque / lista\n",
    "    2. Ultimo elemento de un deque / lista\n",
    "    3. Un elemento distinto del último o el primero (ej: el elemento de la mitad de un arreglo).\n",
    "\n",
    "3. El módulo `bisect` permite hacer búsquedas rápidas en arreglos ordenados. la función `bisect.bisect` permite encontrar el índice en cual insertar un elemento, manteniendo el orden del arreglo operado. \n",
    "    1. Genere la lista ordenada 'ordered_list'  de números entre 0 y 10.\n",
    "    2. Elimine el cuarto elemento de la lista, guarde su valor en la variable `dropped`. Se debe hacer en una linea de código. \n",
    "    3. Importe el módulo `bisect` y utilice el comando `bisect.bisect(ordered_list,dropped)`. ¿Qué significa el valor retornado por la función?¿qué operación se efectúa por medio del comando recién aplicado?\n",
    "    4. Haga un código de referencia para comparar las funciones `list.index()` y `bisect.bisect()` por medio de perfilamiento temporal. Para comprobar sus resultados utilice el hecho de que  el tiempo de ejecución para `bisect.bisect` es de $O(\\log(N)$, mientras que el de `list.index()` es de $O(N)$. \n",
    "    5. Estudie la función `bisect.bisect_left`. \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimización de Operaciones con Diccionarios\n",
    "\n",
    "La gran flexibilidad de los diccionarios los hacen un objeto central en el uso de Python. Estos son implementaciones de *hash maps*, es decir, son estructuras de datos construidas por medio de asociaciones *llave - valor*, donde a cada llave, se asigna un índice especifico, de tal manera que el valor de tal índice puede ser ordenado en un arreglo. Por tal motivo, los diccionarios son altamente eficientes en procesos de eliminación, acceso e inserción teniendo un tiempo promedio de ejecución de $O(1)$. \n",
    "\n",
    "Para acceder a los índices dados por el *hash map* se puede utilizar la función `hash` de Python, esta opera sobre distintos tipos de datos.\n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "Se aplica `hash` a diferentes objetos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('hash string: ',hash('MA6202'))\n",
    "print('hash int:' , hash(1234))\n",
    "print('hash tuple', hash(('a','b','c')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un objeto puede ser operado por `hash` (*hashable object*) si tiene un método `__hash__` y puede ser comparado por medio de `__eq__` por ejemplo. Si un objeto es *hashable* significa que puede ser utilizado como llave de un diccionario, en general, todos los objetos inmutables de Python son *hashables* mientras que las listas y diccionarios, por ser inmutables, no lo son.  \n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "Es posible usar las ventajas de accesibilidad de diccionarios agrupar listas de manera eficiente. Para esto se utiliza el objeto `defaultdict` de la librería `collections`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se construye la lista a agrupar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_group = [('a', 1), ('b', 2), ('c', 3), ('b', 4), ('d', 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los objetos `defaultdict` son subclases de `dict`. Reciben como argumentos un valor inicial para su el atributo `.default_factory`, cuyo valor por defecto es `None`. \n",
    "\n",
    "Los objetos `defaultdict` poseen todas las funcionalidades de un diccionario pero añaden el método `.__missing__()` con el cual se proveen valores por defecto, los cuales se asignan a una nueva llave, es decir, permiten inicializar diccionarios entregando solo el valor de la llave (y no su valor asociado), pues a cada llave nueva, se asigna un valor por defecto de manera automática. \n",
    "\n",
    "Según lo enterior, inicializar un objeto `defaultdict` por medio de `defaultdict(list)` genera un diccionario, en el cual, cada llave nueva tendrá asociada una lista vacía (valor por defecto del atributo `.default_factory` para este tipo de dato)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = defaultdict(list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez teniendo el diccionario definido, es posible agrupar los elementos de la lista `to_group` y se perfila por medio de:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "D = defaultdict(list)\n",
    "\n",
    "for k, v in to_group:\n",
    "    D[k].append(v)\n",
    "\n",
    "sorted(D.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El código anterior genera las llaves `k`, que por defecto poseen una lista vacía asociada, a cada lista vacía agregan por medio de `append` (tiempo de ejecución constante) el elemento inspeccionado `v`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se implementa la misma funcionalidad usando ciclos `for` y `append` de listas, se perfila utilizando `%%timeit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "L = []\n",
    "for elem in to_group:    \n",
    "    if len(L) == 0:\n",
    "        L.append((elem[0],[elem[1]]))\n",
    "    else:\n",
    "        c = 0\n",
    "        for l in L:\n",
    "            if l[0] == elem[0]:\n",
    "                l[1].append(elem[1])\n",
    "                c = 1\n",
    "        if c == 0:\n",
    "             L.append((elem[0],[elem[1]]))\n",
    "\n",
    "L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con lo anterior apreciamos una ganancia en eficiencia, que tambien se traduce en simpleza."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicios**\n",
    "\n",
    "Los objetos `defaultdict` permiten además aumentar la eficiencia al momento de contar elementos de un arreglo. Para ver esto, implemente una función que:\n",
    "\n",
    "1. Reciba una *iterable* como argumento.\n",
    "2. Inicalice un objeto `defaultdict` con tipo de dato `int`. ¿Qué valor se asocia por defecto?.\n",
    "3. Recorra cada elemento del iterable, registrando su número de ocurrencias en una llave del objeto `defaultdict` antes inicializado.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El módulo `collections` permite implementar el procedimiento del ejercicio 2 anterior por medio de la clase `Counter`\n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "Se cuentan los elementos de una lista por medio de la clase `Counter`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "lista = np.random.randint(0, 10, size=100)\n",
    "counts = Counter(lista)\n",
    "\n",
    "sorted(counts.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obs**: El método de counteo por medio de la clase `Counter` tiene un tiempo de ejecución de $O(N)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra ventaja de los diccionarios es que permiten buscar palabras de manera rápida en una lista de documentos, en este caso, tal lista de documentos viene representada dada por:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('text.txt','r') as file:\n",
    "    lines = file.readlines()\n",
    "    lines = [l.rstrip(' \\n') for l in lines]\n",
    "        \n",
    "lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "supongamos que se busca la palabra 'imaginario' en cada documento, es posible generar una lista de documentos con tal palabra por medio de:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_search = 'imaginario'\n",
    "%timeit found = [line for line in lines if to_search in line]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se debe considerar que el tiempo de ejecución asociado a consultar por una palabra es $O(N)$. Para mejorar esto, se puede construir un diccionario, donde a cada palabra se asocie un índice, donde este último corresponde al la linea (o documento si se prefiere) al que pertenece. Esto se puede hacer mediante el siguiente código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = defaultdict(list)\n",
    "\n",
    "for i, line in enumerate(lines):\n",
    "    \n",
    "    for word in line.split():\n",
    "        index[word].append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el diccionario generado, hacer búsquedas es de orden $O(1)$, luego para la misma consulta antes hecha se tiene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "res = index[to_search]\n",
    "[lines[i] for i in res]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es decir, un aumento substancial de rendimiento. Cabe mencionar, que este procedimiento solo tiene sentido si se busca hacer una cantidad alta de consultas sobre un arreglo de lineas/documentos, esto pues, el tiempo de preprocesamiento para generar el indexado por diccionario puede ser muy alto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimización de Operaciones con Conjuntos\n",
    "\n",
    "A diferencia de las listas, los conjuntos son colecciones no ordenadas, donde cada elemento debe ser único. La implementación de conjuntos en Python sigue la misma lógica de los diccionarios en cuanto ambos utilizan funciones *hash*. Por tal motivo, en conjuntos se tienen operaciones rápidas para añadir, eliminar y acceder a elementos. (Del orden $O(1)$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio**\n",
    "\n",
    "Los tiempos de ejecución para los métodos `A.union(B)`, `A.intersection(B)` y `A.difference(B)` son $O(a+b)$, $O(\\min(a,b))$ y $O(a)$, donde $a = |A|$ y $b = |B|$. \n",
    "\n",
    "1. Construya una función de referencia para cada método y utilice un perfilamiento adecuado para comprobar la afirmación anterior de manera empírica. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede hacer uso de conjuntos para efectuar consultas rápidas.\n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "Se utiliza el objeto `index` creado para hacer búsquedas sobre texto. Se consulta sobre los documentos donde las palabras 'imaginario' y 'vive' ocurren simultáneamente, se obtiene un estimado del tiempo de ejecución."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_search = ['imaginaria', 'vive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "res_0 = [lines[i] for i in index[to_search[0]]]\n",
    "res_1 = [lines[i] for i in index[to_search[1]] ]\n",
    "\n",
    "[r for r in res_1 if r in res_0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede modificar la función de indexación para que opere sobre conjuntos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_set = defaultdict(set)\n",
    "\n",
    "for i, line in enumerate(lines):\n",
    "    \n",
    "    for word in line.split():\n",
    "        index_set[word].add(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "luego se hace la misma búsqueda por medio de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "index_set[to_search[0]].intersection(index_set[to_search[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este apartado se ve un incremento substancial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimización con uso de Memoización\n",
    "\n",
    "También se puede mejorar el rendimiento de aplicaciones por medio de un uso eficiente de la memoria, una de las ideas tras esta premisa es la de guardar los resultados de operaciones intensivas en un espacio de memoria llamado *cache*, este espacio puede estar ubicado en memoria (RAM), disco o almacenada de manera remota. El acto de guardar resultados en memoria para luego utilizarlos de manera directa se denomina **memoización**. y es una forma de *chaching* o uso de memorias *cache*.\n",
    "\n",
    "Python ofrece el decorador `@lru_cache` accesible desde la librería base `functools`. Este decorador puede ser utilizado de manera sencilla para guardar resultados en memoria y luego accederlos. \n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "Se utiliza el decorador `@lru_cache` sobre una función sencilla. En primera instancia se importa el módulo necesario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import lru_cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se define la función a memoizar y se aplica el decorador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache\n",
    "def simple_func(x, y):\n",
    "    '''Funcion de prueba para memoizar.'''\n",
    "\n",
    "    print('Obteniendo el resultado...')\n",
    "\n",
    "    return x**y + y**x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para comprobar el funcionamiento del decorador se llama la función dos veces sobre el mismo argumento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = (2,5)\n",
    "simple_func(*args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se repite el procedimiento "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_func(*args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este último caso se observa que el resultado es obtenido directamente desde la memoria. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicios**\n",
    "\n",
    "`@lru_cache` es un decorador que acepta argumentos de entrada, permitiendo el uso del `max_size`. Con este parámetro se especifica el tamaño máximo de memoria para el cache asociado a la función. \n",
    "\n",
    "1. Decore la función anterior indicando como parámetro `max_size = 8`.\n",
    "\n",
    "2. ¿Qué ocurre cuando se llena el tamaño maximo y se realizan más cálculos? *Hint*: lru significa *least recently used*.\n",
    "\n",
    "3. Acceda a la información del *cache* por medio del método `.cache_info()` de la función decorada. ¿Qué significa *hit* y *miss* en este contexto?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un ejemplo más avanzado es el de memoizar funciones recursivas\n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "Se trabaja con la función `factorial` almacenando sus resultados en *cache*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def factorial(n):\n",
    "    if n == 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return n * factorial(n-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se mide el tiempo de ejecución para `n=1000`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "factorial(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se memoiza la función y se repite el experimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache\n",
    "def factorial(n):\n",
    "    if n == 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return n * factorial(n-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "factorial(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con lo que se comprueba la eficiencia del método. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicios**\n",
    "\n",
    "1. Programe secuencia de Fibonacci, perfile su consumo de tiempo y luego compare con una versión memoizada.\n",
    "\n",
    "2. Instale el módulo `joblib`. Este módulo permite guardar resultados en disco por medio del objeto `Memory`. Utilice el decorador `@memory.cache` para memoizar as funciones anteriores (factorial y fibonacci). Compare los tiempos de ejecución al guardar los resultados en disco vs ram."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obs**: La ventaja de utilizar técnicas de *caching* tienen un costo, este radica en aumentar el consumo de memoria, si esta memoria esta localizada en disco, el acceso puede ser muy lento y el rendimiento puede decaer drásticamente. Antes de usar este tipo de estrategias, se recomienda estudiar la factibilidad, teniendo en cuenta las politicas de almacenamiento y acceso de los resultados y su relación con el rendimiento del programa que se desea implementar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimización con uso de Compresiones y Generadores\n",
    "\n",
    "Las compresiones de lista están altamente optimizadas en Python y por tanto puede ser utilizadas para reemplazar ciclos `for` en ciertas circunstancias. \n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "Es posible ganar un mayor rendimiento al utilizar comprensión de listas en vez del ciclo `for` en el siguiente código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(10e4)\n",
    "\n",
    "def for_loop(n=n):\n",
    "    res = []\n",
    "    for i in range(n):\n",
    "        res.append(i*(i+1) - i**2)\n",
    "    \n",
    "    return sum(res)/n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se mide su consumo de tiempo por medio de `%%timeit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "for_loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se implementa la misma función haciendo uso de compresión de listas y de diccionarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_comp(n=n):\n",
    "    return sum([i*(i+1) - i**2 for i in range(n)])/n\n",
    "    \n",
    "def dic_comp(n=n):\n",
    "    return sum({i: i*(i+1) -i**2 for i in range(n)})/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "list_comp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "dic_comp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el caso de compresión de listas vemos una mejoría, por su parte, en compresión de diccionarios, podemos esperar que operaciones de reducción sean más lentas pues se hace uso de llaves. \n",
    "\n",
    "En términos de memoria, cada compresión de listas (o diccionarios) ocupa un nuevo espacio, lo cual aumenta el uso de memoria. Para atacar este problema, se puede hacer uso de **generadores**. \n",
    "\n",
    "Un generador es un iterable que guarda que posee memoria solo de su estado actual y una regla de cambio para el estado siguiente. \n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "La función `map` toma como argumentos una función y un iterator, el resultado de su aplicación es un generador. Para estudiar el comportamiento de este tipo de objetos se construyen dos funciones y se perfilan ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%file bench_module.py -a\n",
    "\n",
    "def list_comp_list(n=int(10e6)):\n",
    "    '''Concatena operaciones sobre comprensiones de lista'''\n",
    "\n",
    "    l_1 = [i**2 for i in range(n) if i % 2 == 0]\n",
    "    l_2 = [i * (i - 1) for i in l_1]\n",
    "\n",
    "    l_3 = [i // 3 for i in l_2]\n",
    "\n",
    "    return max(l_3) / n**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "se construye la misma función utilizando generadores `map`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%file bench_module.py -a\n",
    "\n",
    "def list_comp_map(n=int(10e6)):\n",
    "    '''Concatena operaciones sobre comprensiones de lista'''\n",
    "\n",
    "    l_1 = map(lambda i: i**2, [i for i in range(n) if i % 2 == 0])\n",
    "    l_2 = map(lambda i: i * (i - 1), l_1)\n",
    "    \n",
    "    l_3 = map(lambda i: i // 3, l_2)\n",
    "\n",
    "    return max(l_3) / n**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "se perfila la memoria utilizada por estas funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%memit list_comp_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%memit list_comp_map()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicios**\n",
    "\n",
    "Se pueden entender los objetos generadores con las estructuras ya vistas. El objetivo de estos ejercicios es revisar ciertos aspectos de interés al usar generadores.\n",
    "\n",
    "1. Se puede definir un generador por medio de *compresnsión de generadores* este tipo de comprensión sigue la misma sintaxis que una compresión usua (listas o diccionarios) solo que se utilizan paréntesis normales (como una '*compresion de tuplas*'). Defina un generador por medio de *compresión de generadores*.\n",
    "\n",
    "2. Se pueden definir generadores a partir de funciones, en este caso, el comando `return` debe ser sustituido por `yield`. Este comando permite que el generador definido sea un iterable, el cual solo guarda su estado actual de ejecución y posee una *regla de transición* dada por el cuerpo de la función. Implemente un generador de secuencias inifinitas. Para ello:\n",
    "    1. Defina una función `infinite_seq`, que no tiene argumentos de entrada. \n",
    "    2. Defina un acumulador de suma por medio de la variable `sum = 0`.\n",
    "    3. Defina un bloque `while True` dentro de este inserte las ordenes `yield sum` y en la linea siguiente `sum +=1`. \n",
    "    4. Itere sobre su generador utilizando el método `next`. Interprete la función de `yield` en el bloque anterior. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uso eficiente de Arreglos con Numpy y Pandas\n",
    "\n",
    "### Uso eficiente con NumPy\n",
    "\n",
    "Como ya se ha discutido, NumPy provee una rutinas altamente eficientes para realizar operaciones matemáticas complejas basándose en arreglos de C y FORTRAN. Esto permite tener velocidades optimas aún cuando Python sea interpretado. Otra de las cualidades de NumPy es que almacena resultados intermedios en memoria, es posible mejorar tal aspecto por medio del paquete `numexpr` , el cual permite optimizar y compilar arreglos de manera rápida.\n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "se definen arreglos de NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(10e7)\n",
    "x, y, z = (np.random.rand(n), np.random.rand(n), np.random.rand(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para obtener las ventajas de `numexpr` es recomendable trabajar con arreglos de gran tamaño. A continiación se utiliza la función `numexpr.evaluate` para procesar una operación entre los arreglos definidos, esta función actúa como `eval` de Python, por lo que recibe un string y lo ejecuta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numexpr import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "evaluate('x + z*y**2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit \n",
    "x + z*y**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio**\n",
    "\n",
    "1. Estudie la documentación de `numexpr` y busque las funciones soportadas por `evaluate`.\n",
    "\n",
    "2. Genere una matriz de distancia entre dos arreglos de NumPy. Esta contiene la distancia euclidiana en cada una de sus componentes. Compare los tiempos de ejecución de obtener tal matriz con solamente con expresiones de NumPy y utilizando `numexpr`. \n",
    "\n",
    "3. Estudie la función `numexpr.set_num_threads()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como consideraciones generales al trabajar con NumPy se puede tener en cuenta:\n",
    "\n",
    "1. Las operaciones *inplace* son más rápidas que sus contrpartes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "se define una operacion *inplace* y se compara con una asignación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(5*10e5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "a = np.random.rand(n)\n",
    "a *= 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "a = np.random.rand(n)\n",
    "b = a * 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Aplicar *reshape* no implica generar una copia, por su parte, trasponer si. Por lo anterior, trasponer utiliza más memoria que cambiar la forma de un arreglo. Vale la pen\n",
    "\n",
    "3. `flatten()` y `ravel()` permiten cambiar la forma de un arreglo a dimensión 1, sin embarog, `flatten()` retorna una copia, mientras que `ravel()` solo lo hace si es necesario. Por tal motivo `ravel()` es más rápido con arreglos de gran tamaño."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "a = np.random.random(size = [n,n])\n",
    "b = a.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "a = np.random.random(size = [n,n])\n",
    "b = a.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Seimrpe mejor utilizar [reglas de broadcasting](https://docs.scipy.org/doc/numpy/user/basics.broadcasting.html) para operar con arreglos de distinto tamaño, es decir, se debe prevenir el uso de `reshape` si es que dos arreglos son compatibles según alguna regla de *broadcasting*. A modo de ejemplo, se estudia el producto externo entre dos arreglos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.random(size = n)\n",
    "a_1 = a[:,np.newaxis]\n",
    "a_2 = a[np.newaxis, :]\n",
    "\n",
    "'''\n",
    "Obs: np.tile permite copiar un arreglo segun un patron (rep_f,rep_c)\n",
    "de esta forma se repite tantas veces por fila como rep_f y tantas\n",
    "veces por columna como rep_c.\n",
    "'''\n",
    "\n",
    "%timeit np.tile(a_1, (1, n)) * np.tile(a_2, (n, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit a_1 * a_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. En arreglos de gran tamaño, donde la precisión no es un problema, se puede reducir el consumo de memoria al disminuir la presición numérica de los elementos del arreglo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a.astype('float16')\n",
    "b.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio**\n",
    "\n",
    "Perfile el uso de memoria y velocidad de ejecución para arreglos de punto flotante de doble presición  `float64`versus punto flotante de presición singular `float32`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otro aspecto a optimizar de Python es la velocidad de los ciclos `for`. Por lo general, estos bloques son inherentemente lentos. \n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "Se construye una función que calcula ciertas operaciones sobre un arreglo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slow_for(n=1000):\n",
    "    arr = np.arange(n)\n",
    "    diff = np.zeros(n-1)\n",
    "    \n",
    "    for i in range(1, n):\n",
    "        diff[i-1] = np.sqrt(arr[i]**2 - arr[i-1]**2)\n",
    "    \n",
    "    return sum(diff)/n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "se estudia su tiempo de ejecución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit slow_for()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para mejorar la velocidad, se puede utilizar la **vectorización** que entrega el broadcasting de arreglos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def for_less(n=1000):\n",
    "    arr = np.arange(n)\n",
    "    diff = np.sqrt(arr[1:]**2 - arr[:-1]**2)\n",
    "    \n",
    "    return sum(diff)/n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "se estudia su tiempo de ejecución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit for_less()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por le general se recomienda cambiar todo ciclo `for` por la versión vectorizada de NumPy (que hace uso de broadcasting de arreglos)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uso eficiente con Pandas\n",
    "\n",
    "Las directrices de manejo eficiente de la librería Pandas, pasan por utilizar métodos de NumPy siempre que sea posible, preferir funciones de agregación de datasets nativas como `merge` y `concat` sobre agregaciones por medio de ciclos `for`. \n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "Se carga un dataset consistente en 24 archivos con información sobre criptomonedas, la primera imeplemtación cosiste en generar un dataset vacío, para completarlo según un clico `for`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -r 10\n",
    "df_1 = pd.DataFrame()\n",
    "for file in glob.glob('data/*.csv'):\n",
    "    df_1 = df_1.append(pd.read_csv(file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para mejorar el rendimiento, se puede aplicar el método `concat` sobre un generador que sintetice el funcionamiento del ciclo `for`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -r 10\n",
    "generator = map(pd.read_csv, glob.glob('data/*.csv'))\n",
    "df = pd.concat(generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Donde se aprecia una mejora considerable. \n",
    "\n",
    "#### Optimizaciones de indexado\n",
    "\n",
    "Pandas ofrece operaciones optimizadas de indexado, estas permiten fusiones de datasets y búsquedas eficientes. En este caso, se debe considerar que fusionar datasets por medio de `merge` es más eficiente cuando se hace utilizando indices.\n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "El dataset `df_comp` contiene información complementarias a `df` donde según el símbolo asociado a cada criptomoneda, se agrega información sobre la variación porcential en las últimas 1, 2 horas y ultimos 7 dias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = map(lambda x: pd.read_csv(x, index_col=0), glob.glob('data/*.csv'))\n",
    "df = pd.concat(generator)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comp = pd.read_csv('data/comp_data/comp_data.csv', index_col= 0)\n",
    "df_comp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se procede a fusionar los datasets según la columan `Simbol`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_merge = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -r 10\n",
    "df_m = to_merge.merge(df_comp, on ='Simbol')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se procede a indexar por `Simbol` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_add = df_comp.copy()\n",
    "\n",
    "to_merge.set_index('Simbol')\n",
    "to_add.set_index('Simbol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -r 10\n",
    "df_m1 = to_merge.merge(to_add, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "con lo que se observa cierta mejora en el rendimiento. En general, al trabajar con datasets de mayor tamaño, esta diferencia en redimiento comienza a ser más notoria. \n",
    "\n",
    "\n",
    "En cuanto al acceso a elementos de un dataframe siempre es más rápido utilizar `iloc` para acceder a arreglos de indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se usa este tipo de merge para conservar los indices iniciales\n",
    "df_m = to_merge.merge(df_comp, on ='Simbol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -r 10\n",
    "# Version sin loc\n",
    "df_m['Volum 24 hores'][[500,400,300,100,50,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -r 10\n",
    "# Version loc\n",
    "df_m.loc[[500,400,300,100,50,1],'Volum 24 hores']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -r 10\n",
    "#Version .iloc\n",
    "df_m.iloc[[500,400,300,100,50,1],5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio**\n",
    "\n",
    "1. Para acceder a registros de un dataframe de manera individual (no consultando por arreglos de registros) existen los métodos `at` e `iat`, análogos a `.loc` e `.iloc` respectivamente. Compare sus rendimientos. Observe que tanto `at` como `iat` realizan inferencia de tipos de datos, pruebe acceder a un valor de un dataframe por medio de `at` y luego asigne un valor con un tipo de dato distinto, ¿qué ocurre?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por lo general, se recomienda evitar utilizar ciclos `for` para iterar sobre objetos de Pandas, pues acceder a valores dentro de este tipo de estructuras tiene un alto costo computacional asociado. En este contexto, se busca vectorizar las operaciones. Cuando no es posible vectorizar, existen ciertos métodos alternativos con los cuales se puede trabajar, esto son `iterrrows()` e `.itertuples()`. A continuación se estudia una transformación sobre la columna `Preu` del dataset `df_m`.\n",
    "\n",
    "En primer lugar, se llevan los datos al formato correcto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m['Preu'] = df_m['Preu'].str.replace('$','')\n",
    "df_m['Preu'] = df_m['Preu'].str.replace(',','')\n",
    "df_m['Preu'] = df_m['Preu'].str.replace('?','0')\n",
    "df_m['Preu'] = df_m['Preu'].astype('float32')\n",
    "df_m['Preu'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se procede a normalizar los valores de `Preu` utilizando distintas técnicas de computo. Acá se comienza con un `for` de acceso eficiente por medio de `iat`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valores iniales\n",
    "df_m.reset_index(inplace=True, drop=True)\n",
    "\n",
    "m = df_m['Preu'].min()\n",
    "M = df_m['Preu'].max()\n",
    "\n",
    "n = len(df_m)\n",
    "\n",
    "norm = lambda x: (x -m)/(M - m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -r 10\n",
    "#For con acceso eficiente\n",
    "\n",
    "price = np.zeros(n)\n",
    "for idx in range(n):\n",
    "    price[idx] = norm(df_m.iat[idx, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se efectua la misma operación utilizando `.iterrows()`. Este método genera un iterable a partir del dataframe sobre el que se opera. Cada elemento de este iterable es de la forma `(index, row)` donde `index` es el indice asociado a una fila y `row` el contenido de tal fila."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -r 10\n",
    "# For con iterrows()\n",
    "price_1 = np.zeros(n)\n",
    "for idx, row in df_m.iterrows():\n",
    "    price_1[idx] = norm(row[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso se observa una ventaja substancial del método de indexado escalar y eficiente `iat`. \n",
    "\n",
    "Otro método de iteración alternativo es `.itertuples()` este se comporta de manera similar a `iterrows()` pero proporciona una *tupla nombrada* como objeto de iteración. Una tupla nombrada se comporta como un diccionario pero solo soporta la notación `tupla_nombrada.elem` para acceder al valor asociado a la llave `elem`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -r 10\n",
    "# For con iterrows()\n",
    "price_2 = np.zeros(n)\n",
    "for row_tuple in df_m.itertuples():\n",
    "    price_2[row_tuple.Index] = norm(row_tuple.Preu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En comparación a los métodos anteriores se tiene una mejora considerable al momento de iterar. \n",
    "\n",
    "Para continuar y a modo de comparación en cuanto a los ordenes de magnitud en tiempos de ejecución, se procede a vectorizar utilizando el método `.map` (forma más básica de vectorizar en Pandas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -r 10\n",
    "price_3 = df_m['Preu'].map(norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acá se evidencia que en efecto el tiempo de ejecución reduce en torno a la mitad. Finalmente, se vectoriza utilizando la notación recomendada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -r 10\n",
    "price_4 = (df_m['Preu'] - m) / (M-m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Donde el tiempo de ejecución es por lo menos un orden de magnitud más rápido. Por último, utilizando las capacidades de vectorización de NumPy, es posible aplicar la operación `norm` directamente sobre el arreglo asociado a los valores de `df_m['Preu']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -r 10\n",
    "data = df_m['Preu'].values\n",
    "norm(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí se ve como la velocidad de ejecución mejora aún más, incluso cuando se incurre en operaciones de acceso de memoria por medio de \n",
    "`data = df_m['Preu'].values`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicios**\n",
    "\n",
    "1. Al igual que NumPy, Pandas se beneficia de la libreria `numexpr`. Estudie la [documentación de Pandas](https://pandas.pydata.org/pandas-docs/stable/user_guide/enhancingperf.html) al respecto y observe cuando es útil usar la expresión `eval()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cython\n",
    "\n",
    "Cython es una extensión de Python, la cual permite declaración de tipo para funciones, variables y clases. Esto permite compilar rutinas de Python,las cuales actúan como código de *C*. \n",
    "\n",
    "Por definición, la sintaxis de Cython contiene a la de Python pero tiene la ventaja de ser compilada. Por lo general, los archivos de código Cython poseen la extensión `.pyx` y se construyen configurando la función `setup` del módulo `setuptools` (ver el ejercicio de esta sección). Por otra parte, la extensión de Jupyter `cython` hace esta tarea de manera automática, compilando el código de una celda determinada.\n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "Se crea una rutina básica de Cython y se compila por medio de la extensión `cython`. Para ello, se carga dicha extensión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext cython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "posteriormente, se define una función sencilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "def funcion_basica_cython(n=int(10e5)):\n",
    "    s = 0\n",
    "    for i in range(n):\n",
    "        s += i**2 - i*(i-1)\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "se implementa la misma función pero utilizando unicamente Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def funcion_basica(n=int(10e5)):\n",
    "    s = 0\n",
    "    for i in range(n):\n",
    "        s += i**2 - i*(i-1)\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "finalmente se comparan los tiempos de ejecución esperados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit funcion_basica()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit funcion_basica_cython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con lo anterior se observa una mejoria en el tiempo de ejecución, esta se logra unicamente pues el código ejecutado a sido compilado y no interpretado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio**\n",
    "\n",
    "El objetivo de este ejercicio es que compile una función de Cython utilizando el *procedimiento estándar*, para ello:\n",
    "\n",
    "1. Cree un módulo de Python, este módulo contiene la función `func`, programe una rutina simple para dicha función utilizando sólo código de Python nativo. Guarde el módulo con el nombre `cython_func.pyx`\n",
    "\n",
    "2. En la misma carpeta donde se encuentra el módulo `cython_func.pyx` escriba el programa `setup.py`. \n",
    "\n",
    "3. En `setup.py`importe la función `setup` del módulo `setuptools`.\n",
    "\n",
    "4. En `setup.py`importe `cythonize` del módulo ` Cython.Build`. \n",
    "\n",
    "4. Configure el módulo a compilar, para ello, en `setup.py` llame la función `setup` entregando como argumento los parámetros `'name'`, `'ext_modules'` y `'zip_safe'`. Estudie el significado de estos en la documentación de Cython. \n",
    "\n",
    "5. Ejecute `setup.py ` desde la consola, para ello se debe ejecutar `python setup.py build_ext --inplace`.¿Cuál es la función de `build_ext`?\n",
    "\n",
    "6. Importe su módulo y cuantifique su tiempo de ejecución en contraste con su versión sin compilar. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tipos Estáticos\n",
    "\n",
    "En Python se tienen variables con tipo *dinámico*, es decir, tales variables pueden cambiar de tipo de dato durante la ejecución de un programa, sin declararlo de manera explicita. Si bien esto hace que el lenguaje sea más felxible, produce una baja en el rendimiento al momento de interpretarse el código. \n",
    "\n",
    "Cython permite el uso de tipos de dato *estáticos*, lo que permite optimizar aún más las rutinas de Python. Para declarar un tipo de dato en Cython, se utiliza la orden `cdef`, está puede ser utilizada en variables y funciones. \n",
    "\n",
    "Para su uso en **variables**, se hace uso de `cdef` y del tipo de dato que se busca declarar. \n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "Para declarar la variable `j` con un tipo de dato entero (estático) se puede ejecutar el siguiente código de Cython:\n",
    "\n",
    "```Cython\n",
    "cdef int j \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio**\n",
    "\n",
    "1. Defina la variable `d` , esta debe ser númerica de punto de flotante con doble precisión. Haga esto desde Cython.\n",
    "\n",
    "2. Asigne un valor con tipo de dato `string` a la variable `d`. ¿Se diferencia el comportamiento de esta asignación con el comportamiento de Python nativo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se procede a estudiar la ventaja en rendimiento que ofrecen los tipos de dato estáticos, para ello, se define la siguiente función"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dynamic_func(n=int(10e5)):\n",
    "    '''Funcion sencilla con variables dinamicas.'''\n",
    "    \n",
    "    s = 0\n",
    "    for i in range(n):\n",
    "        s += i**2 - i - 1\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se prueba su eficiencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit dynamic_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se define la misma función usando Cython y se mide el tiempo de ejecución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "def dynamic_func_cython(n=int(10e5)):\n",
    "    '''Funcion sencilla con variables estaticas preprocesada por Cython.'''\n",
    "    \n",
    "    s = 0\n",
    "    for i in range(n):\n",
    "        s += i**2 - i - 1\n",
    "\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit dynamic_func_cython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente se declaran tipos de dato estáticos y se mide el tiempo de ejecución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "def static_func_cython(n=int(10e5)):\n",
    "    '''Funcion sencilla con variables estaticas.'''\n",
    "    \n",
    "    cdef int i, s=0\n",
    "    \n",
    "    for i in range(n):\n",
    "        s += i**2 - i - 1\n",
    "\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit static_func_cython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con lo que se observa una mejora substancial en el rendimiento. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio**\n",
    "\n",
    "Cython se relaciona intimamente con *C*, por tal motivo, es posible realizar algunas operaciones de tal lenguaje de manera nativa en Cython. \n",
    "\n",
    "1. Defina la variable `x=1` estática tipo *int* en cython. Defina la variable `y` estática tipo `double` en cython. Finalmente ejecute `y = <double> x`. ¿Qué efecto tiene el comando `<double>` en la orden anterior?\n",
    "\n",
    "2. El método anterior se denomina *cast* y es nativo en *C*. Investigue otros métodos de *casting* de potencial utilidad en Cython.\n",
    "\n",
    "3. Declare la variable `obj = 'ejercicio'` de tipo estático `object`. Ejecute la orden `obj = 1`.¿Se espera algún tipo de error en la ejecución?¿utilizar este tipo de datos mejora el rendimiento en comparación a trabajar con tipos de datos dinámicos?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cython permite declarar tipos de datos estáticos más especificos para **funciones**, en este caso, las funciones declaradas con datos estáticos funcionan de la misma manera que una función nativa de Python, con la excepción de que se realiza un revisión de argumentos (*type checking*) al ser ejecutadas. La sintaxis a utilizar es:\n",
    "\n",
    "```cython\n",
    "cdef res_dtype func(dtype_1 var_1, ..., dtype_n var_n):\n",
    "    res = do_stuff(var_1,var_2,..., var_n)\n",
    "    return res\n",
    "```\n",
    "\n",
    "En este caso `res_dtype` corresponde al tipo de dato esperado como resultado de la función, mientras que `dtype_1, dtype_2, ..., dtype_n` corresponden los tipos de dato esperados como input de la función. Las funciones definidas por este procedimiento son transformadas a código *C* pero **no pueden ser accedidas desde Python**, por lo tanto, para utilizarlas, se deben llamar dentro de scripts de Cython (archivos `.pyx` ejecutados por medio de la orden `cython`). Una manera de resolver el conflicto anterior y poder acceder a funciones de Cython desde Python, es por medio de la creación de módulos de Cython.\n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "Se implementa un módulo de Cython, este posee sólo una función"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file func_module.pyx\n",
    "def func(x):\n",
    "    return x**3 + 2*x**2 + 3*x + 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se construye el archivo de configuración correspondiente y se guarda en `setup.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file setup.py\n",
    "from setuptools import setup\n",
    "from Cython.Build import cythonize\n",
    "\n",
    "setup(\n",
    "    name='modulo test de funciones',\n",
    "    ext_modules=cythonize(\"func_module.pyx\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, se construye el módulo de Cython, para ello, se ejecuta `python setup.py build_ext --inplace` en la consola. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#En maquinas con windows este script puede no funcionar\n",
    "!python setup.py build_ext --inplace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con lo anterior se crea un archivo `.c` con el nombre del módulo. Finalmente para trabajar con el módulo creado, se importa de manera estándar por medio de:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from func_module import func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "se estudia su tiempo de ejecución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit func(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se compara el tiempo de ejecución con el de la implementación que utiliza Python directamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_python(x):\n",
    "    return x**3 + 2*x**2 + 3*x + 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit func_python(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con lo que se aprecia una mejora en el rendimiento al usar Cython.\n",
    "\n",
    "Otra forma de acceder a funciones de Cython desde Python, es por medio del comando `cpdef`. Al utilizarlo, Cython genera 2 versiones de la función a definir, una accesible desde Cython y otra accesible desde Python, esta última, se carga en el entorno de Python al ser definida. La sintaxis de `cpdef` es equivalente a la de `cdef`.\n",
    "\n",
    "```cython\n",
    "cdef res_dtype func(dtype_1 var_1, ..., dtype_n var_n):\n",
    "    res = do_stuff(var_1,var_2,..., var_n)\n",
    "    return res\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se define la función anterior por medio de `cpdef` y se prueba su rendimiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "cpdef func_cpdef(x):\n",
    "    return x**3 + 2*x**2 + 3*x + 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit func_cpdef(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "aqui se observa un comportamiento analogo al de importar una función definida por `cdef`. Finalmente se crea una verisón con tipos de dato estáticos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "cpdef double func_cython(double x):\n",
    "    return x**3 + 2*x**2 + 3*x + 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit func_cython(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este último caso se observa un mejora notoria en el rendimiento. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con respecto a la relación entre `def`, `cdef` y `cpdef` es bueno tener en cuenta:\n",
    "\n",
    "1. Las funciones definidas por `def` son llamadas por medio de Python y por tanto interpretadas, lo que las hace inherentemente más lentas. Sin embargo, son extremadamente flexibles pues operan con objetos genéricos. \n",
    "\n",
    "2. La funciones definidas con `cdef` son traducciones de Python a *C*. Sus tipos deben ser declarados para ganar un rendimiento significativo. Por ser funciones de *C*, las funciones `cdef` no son visibles de manera nativa por Python.\n",
    "\n",
    "3. Las funciones definidas por medio de `cpdef` generan funciones `def` y `cdef` adjuntas. En este caso la función `def` esta enlazada directamente a la `cdef` y puede ser ejecutada desde Python.\n",
    "\n",
    "Por lo anterior, es recomendable optimizar utilizando funciones `cdef` (o `cpdef` si se desea) cuando se incurre en cálculos que debe ser realizados múltiples veces, más aún, en tales funciones se alcanza máxima eficiencia cuando se declaran tipos de dato estáticos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dentro de **clases**, se pueden definir funciones y variables estáticas utilizando `cdef`. En este caso, se utiliza la sintaxis:\n",
    "\n",
    "```cython\n",
    "cdef class ClaseEstatica:\n",
    "    # Tipos de datos estaticos\n",
    "    cdef dtype_1 var_1\n",
    "    ...\n",
    "    cdef detype_n var_n\n",
    "    \n",
    "    # Metodos de Python \n",
    "    def normal_method(self,*args,**kwargs):\n",
    "        do_stuff(self,*args,**kwargs)\n",
    "        \n",
    "    # Metodos de Cython\n",
    "    cpdef res_dtype cython_method(self,*args,**kwargs):\n",
    "        do_stuff(self,*args,**kwargs)\n",
    "    \n",
    "```\n",
    "\n",
    "Las clases de Python pueden heredar de clases `cdef` pero no se tiene la relación reciproca. Por otra parte, Cython sólo permite herencia simple. \n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "Se define una estructura clases en Cython, se almacena dicha estructura en un módulo de Cython para asegurar su disponibilidad. En primer lugar se define la clase `Function`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "cdef class Function:\n",
    "    '''Objeto que abstrae el concepto de funcion'''\n",
    "    \n",
    "    cpdef double apply(self, double x):\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego se define una clase que hereda de `Function` y anula el método de Cython `.apply()`, para que Jupyter reconozca la relación de herencia es necesario definir todas las dependencias en la misma celda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "cdef class Function:\n",
    "    '''Objeto que abstrae el concepto de funcion'''\n",
    "    \n",
    "    cpdef double apply(self, double x):\n",
    "        return 1\n",
    "    \n",
    "cdef class Poly(Function):\n",
    "    '''Funcion polinomial.'''\n",
    "    \n",
    "    cdef int d\n",
    "    \n",
    "    def __init__(self, int d):\n",
    "        self.d = d\n",
    "        \n",
    "    cpdef double apply(self, double x):\n",
    "        return sum([x**d for d in range(self.d)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que la clase `Poly` se inicializa y opera como corresponde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Poly(5)\n",
    "print('Resultado de p(5):', p.apply(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No obstante, si se desea acceder al atributo `.d`, no es posible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    print('El valor de p.d es: ', p.d)\n",
    "        \n",
    "except AttributeError:\n",
    "    print('No fue posible acceder a p.d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para declarar atributos públicos en Cython se utiliza la orden `public`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "cdef class Function:\n",
    "    '''Objeto que abstrae el concepto de funcion'''\n",
    "    \n",
    "    cpdef double apply(self, double x):\n",
    "        return 1\n",
    "    \n",
    "cdef class Poly(Function):\n",
    "    '''Funcion polinomial.'''\n",
    "    \n",
    "    # Se agrega la orden public\n",
    "    cdef public int d\n",
    "    \n",
    "    def __init__(self, int d):\n",
    "        self.d = d\n",
    "        \n",
    "    cpdef double apply(self, double x):\n",
    "        return sum([x**d for d in range(self.d)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se intenta acceder nuevamente a `p.d`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Poly(5)\n",
    "\n",
    "try:\n",
    "    print('El valor de p.d es: ', p.d)\n",
    "        \n",
    "except AttributeError:\n",
    "    print('No fue posible acceder a p.d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con lo que se logra lo buscado. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las clases de Cython se conocen también como *tipos extendidos*, esto quiere decir, que al utilizar `cdef class` se está creando un nuevo tipo de dato. Utilizando el código anterior, se agrega una función que toma objetos tipo `Poly` y entrega una transformación de estos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "cdef class Function:\n",
    "    '''Objeto que abstrae el concepto de funcion'''\n",
    "    \n",
    "    cpdef double apply(self, double x):\n",
    "        return 1\n",
    "    \n",
    "cdef class Poly(Function):\n",
    "    '''Funcion polinomial.'''\n",
    "    \n",
    "    # Se agrega la orden public\n",
    "    cdef public int d\n",
    "    \n",
    "    def __init__(self, int d):\n",
    "        self.d = d\n",
    "        \n",
    "    cpdef double apply(self, double x):\n",
    "        return sum([x**d for d in range(self.d)])\n",
    "    \n",
    "#Se utiliza return void pues la funcion no retorna valores,\n",
    "cpdef void transform(Poly p):\n",
    "    p.d += 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe que el tipo de dato retornado es *void* (la función no retorna valores) y el tipo de dato input es *Poly*. Se prueba el funcionamiento del procedimiento anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Poly(5)\n",
    "print('Valor de p.d antes de transformar:', p.d)\n",
    "transform(p)\n",
    "print('Valor de p.d despues de transformar:', p.d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trabajo con módulos de Cython\n",
    "\n",
    "Al trabajar con módulos, es necesario diseñar la organización de las funciones y clases implementadas. Los módulos de Cython no son lo excepción. Dentro de sus características, se tiene la existencia de *archivos de definición* o *header files*, similares a librerias de *C*. Por otra parte, la interacción entre módulos de Cython se rige por un comportamiento más bien similar al de Python por medio del comando `cimport`. \n",
    "\n",
    "Los archivos *header* de Cython tienen extensión `.pxd` y se utilizan como una interfaz entre Cython  código de C. La idea de estos archivos es servir de enlace entre las *declaraciones* ,*prototipos* o definiciones de funciones y tipos de datos con su implementación en *C* (o en un archivo `.pyx`)\n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "Se construye un módulo de Cython para las funciones promedio aritmético y geométrico de dos números . En primera instancia se definen las funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file header_example.pyx\n",
    "cdef double mean(double x, double y):\n",
    "    return (x+y)/2\n",
    "\n",
    "cdef double geo_mean(double x, double y):\n",
    "    return pow(x*y,0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para compartir las definiciones de `mean` y `geo_mean`, se genera un archivo *header*, observe que solo contiene las definiciones de las funciones involucradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file header_example.pxd\n",
    "cdef double mean(double x, double y)\n",
    "cdef double geo_mean(double x, double y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Según el método anterior, se puede importar el módulo `header_example` en cualquier rutina de Cython por medio de `cimport`, se construye la rutina `medias.pxy` que recibe 2 números y entrega una transformación entre su promedio arimético y geométrico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file transform.pyx\n",
    "from header_example cimport mean, geo_mean\n",
    "\n",
    "cpdef double transformer(double x,double y):\n",
    "    return (mean(x,y)**2 - geo_mean(x,y))*0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente para ejecutar la función `transformer`, es necesario configurar el módulo correspondiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file setup_3.py\n",
    "from setuptools import setup\n",
    "from Cython.Build import cythonize\n",
    "\n",
    "setup(ext_modules=cythonize([\"header_example.pyx\", \"transform.pyx\"]),\n",
    "     zip_safe = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python setup_3.py build_ext --inplace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se verifica el correcto funcionamiento al importar la función `transformer`. Observe que es posible utilizar dicha función desde Python, pues fue definida por medio de `cpdef`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transform import transformer\n",
    "transformer(1,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arreglos de Cython, Numpy y C\n",
    "\n",
    "Una de las grandes ventajas de *C* en cuanto a rendimiento es su manejo de arreglos. Si bien estos son rápidos debido a su *bajo nivel* presentan un gran desafio en su manejo, pues requieren de especificaciones en cuanto a tipos de dato y espacios de memoria (por medio de direcciones y punteros). No obstante, Cython provee una manera sencilla de interactuar con estas estructuras. \n",
    "\n",
    "Los arreglos *C* son secuencias contenedoras de bajo nivel. Para comprender estas secuencias, es necesario comprender el significado del término *memory address* o *dirección de memoria*. En *C* una dirección de meoria corresponde a la ubicación del espacio de memoria utilizada por una estructura o variable, se denota por el símbolo `&`. \n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "Si se declara una variable tipo `float` de precisión simple, se posicionan 32 bits de memoria, la posición en la cual se encuentra la información de la variable (donde se encuentran esos 32 bits) es su dirección de memoria. Para obtener acceso a tal dirección, se utiliza el símbolo `&`. \n",
    "\n",
    "**Obs**: Para imprimir valores en pantalla usando *C*, se utiliza la función `printf` del módulo `libc.stdio`. No es posible usar la función nativa `print` de Python en este caso, pues no puede convertir direcciones de memoria a objetos interpretables. Por otra parte, los resultados de `printf` son del tipo `std output` o *salida estándar*, este tipo de salidas son las que se imprimen en la consola, lamentablemente IPython (y por tanto Jupyter) no interactúa con outputs de tipo estándar de manera nativa. Por lo anterior, se utiliza la librería `wurlitzer` que captura salidas estándar asociadas a un programa de Python y las imprime en la consola de IPython."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "from wurlitzer import sys_pipes\n",
    "from libc.stdio cimport printf\n",
    "\n",
    "cdef float a \n",
    "\n",
    "with sys_pipes():\n",
    "    printf(\"%p\",&a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultado de esta operación es la dirección de memora de la variable `a`de tipo `float`. Para almacenar direcciones de memoria, se puede hacer uso de una estructura especial denominada *puntero* o *pointer* en inglés. Estos se declaran usando `*` como prefijo. Si se quisiera almacenar la dirección de memoria de la variable `a`, se debe declarar un puntero de tipo `float`, esto se hace de la siguiente manera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "cdef float a\n",
    "cdef float *b\n",
    "b = &a "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso `b` es un puntero que hace referencia a la dirección de memoria de la variable `a`. Si se quiere acceder a la información ubicada en la dirección de memoria referenciada por un puntero `p` se utiliza la notación `p[0]`.\n",
    "\n",
    "**Obs**: Si bien acceder usando `p[0]` es un comportamiento aceptado en *C*, la manera habitual de hacerlo es por medio del operador de *deferencia* `*`, en algunas implementaciones de Cython, usar dicho operador puede generar problemas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "from wurlitzer import sys_pipes\n",
    "from libc.stdio cimport printf\n",
    "\n",
    "cdef float a\n",
    "cdef float *b = &a\n",
    "\n",
    "a = 2.0\n",
    "\n",
    "with sys_pipes():\n",
    "    printf(\"Valor de &a: %p \\n\", &a)\n",
    "    printf(\"Valor de b : %p \\n\", b)\n",
    "    printf(\"Valor de a : %f \\n\", a)\n",
    "    printf(\"Valor de *b: %f \\n\", b[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con lo anterior se deduce que `*p = &var` hace que la dirección de memoria de `var` se guarde en la variable tipo *puntero* `p`. El valor asociado a la variable `var` será almacenado en `p[0]` si `var` es una constante. \n",
    "\n",
    "El caso general corresponde a declarar arreglos de *C*, en este proceso, el programa posiciona una cantidad de espacio de memoria solicitada. Por ejemplo, se se desea crear un arreglo de datos `float` con 5 elementos, se reserva el espacio correspondiente a 4 bytes (o 32 bits) para cada uno de los 5 elementos, este espacio (de 40 bytes en total) consite de bloques contiguos de memoria. \n",
    "\n",
    "En cython es posible declarar arreglos de *C* por medio de \n",
    "```cython\n",
    "cdef dtype arr[n]\n",
    "```\n",
    "donde `dtype` es el tipo de dato contenido, `arr` es el nombre del arreglo y `n` la cantidad de elementos solicitados. \n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "Se declara un arreglo consistente en 10 arreglos de 3 elementos `float`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "cdef float matrix[10][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, la memoria se posiciona fila por fila, de esta manera, si la primera fila de `matrix` es el arreglo `[0,1,2]` y la segunda `[33,44,55]`, la primera sección de memoria asociada a `matrix` será aquella que corresponde a los elementos 0,1,2,33,44,55,..., hasta agotar las filas de `matrix`. Finalmente, `matrix[0]` hace referencia al primer arreglo `[0,1,2]`, mientras que `matrix[1]` al segundo y así sucesivamente. \n",
    "\n",
    "Es conveniente pensar en los arreglos multidimensionales, como arreglos de arreglos, en este caso, se tienen 10 arreglos de 3 elementos, pero no hay restricción en la cantidad de *niveles* a declarar.\n",
    "\n",
    "Lo comentado anteriormente tiene una consecuencia pŕactica, y es que cuando se itera sobre arreglos, es necesario tener en cuenta sobre qué dimensión es más eficiente iterar. Esto pues, si por ejemplo en `matrix` recorremos por la primera dimensión, se accede a elementos *no contiguos* en memoria lo cual hace que el acceso a los elementos sea más lento. Por otra parte, si se itera sobre la última dimensión, siempre se accede a elementos contiguos en memoria. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio**\n",
    "\n",
    "1. Investigue como se almacenan arreglos de más de 2 dimensiones en *C*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los arreglos de *C* no soportan *slicing* pero se accede a sus elementos utilizando una notación similar a la Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "from itertools import product as prod\n",
    "\n",
    "cdef int matrix[10][3]\n",
    "cdef int i,j\n",
    "\n",
    "for i,j in prod(range(10),range(3)):\n",
    "    matrix[i][j] = i + j\n",
    "\n",
    "print('Elemento matrix[0][0]: ', matrix[0][0])\n",
    "print('Elemento matrix[4][2]: ', matrix[4][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existe una estrecha relación entre punteros y arreglos. En arreglos, de hecho, la variable asociada al arreglo en realidad apunta a la dirección de memoria asociada a su primer elemento. \n",
    "\n",
    "En el siguiente código se genera un arreglo de dos dimensiones (arreglo de arreglos), se crea un puntero hacia su dirección de memoria. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "from libc.stdio cimport printf\n",
    "\n",
    "from wurlitzer import sys_pipes\n",
    "from itertools import product as prod\n",
    "\n",
    "cdef int i, j\n",
    "cdef int matrix[10][3]\n",
    "cdef int (*p)[10][3]\n",
    "\n",
    "p = &matrix\n",
    "\n",
    "for i,j in prod(range(10),range(3)):\n",
    "    matrix[i][j] = i + j\n",
    "\n",
    "with sys_pipes():\n",
    "    printf(\"%p \\n\", matrix)\n",
    "    printf(\"%p \\n\", matrix[0])\n",
    "    printf(\"%p \\n\", &matrix[0][0])\n",
    "    printf(\"%p \\n\", p[0])\n",
    "    printf(\"%p \\n\", p[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con lo anterior se confirma que la variable `matrix` apunta a la dirección de memoria de su primer elemento `matrix[0]` que a la vez es un arreglo de tres dimensiones, el cual apunta a la dirección de memoria de su primer elemento `&matrix[0][0]`. Esto es equivalente a definir un puntero `p` que almacena la dirección de memoria `&matrix` y acceder a su primer elemento `p[0]` que es un puntero asociado a `&matrix[0][0]` y que por tanto se puede acceder por medio de `p[0][0]`.\n",
    "\n",
    "El uso de arreglos y punteros de *C* es comendado cuando se busca utilizar librerías de *C* en conjunción con rutinas de Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arreglos de Numpy en Cython\n",
    "\n",
    "Los arreglos de NumPy se pueden utilizar como objetos normales de Python en Cython, la ventaja de esto, es que se hereda el rendimiento de los métodos de *broadcasting*. \n",
    "\n",
    "Cython posee un módulo NumPy propio, la oportunidad que esto ofrece, es evitar operaciones realizadas por el interprete de Python en operaciones de acceso a arreglos. \n",
    "\n",
    "Los arreglos Numpy pueden ser declarados con el tipo de dato `ndarray` dentro de Cython, para ello, es necesario importar `numpy` por medio de `cimport`.\n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "Se importa `numpy` en Cyhton y se declara el arreglo `vec` utilizando el tipo de dato `ndarray`. El arreglo`vec` será unidimensional y contendrá elementos de tipo `double`. Para declararlo, se utiliza:\n",
    "\n",
    "```cython\n",
    "cdef ndarray[double, ndim=1] vec\n",
    "```\n",
    "\n",
    "La notación del tipo `cdef ndarray[dtype, ndim] var`, que hace uso de paréntesis `[]` se denomina *buffer sintax*, este tipo de sintaxis no se permite en el *scope* global de un módulo de Cython por lo que ejecutar directamente dicha orden produce un error. Para solucionar dicho problema, se crea un nuevo *scope* por medio de una función con la cual se accede a la variable.\n",
    "\n",
    "A continuación se crea una función que opera sobre un arreglo de NumPy por medio de Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "cimport numpy as np_c\n",
    "import numpy as np\n",
    "\n",
    "cpdef np_c.ndarray[double, ndim = 1] vec_func(int d):\n",
    "    \n",
    "    cdef np_c.ndarray[double, ndim = 1] vec\n",
    "    vec = np.zeros((d,), dtype = 'float')\n",
    "    \n",
    "    cdef int i\n",
    "    for i in range(d):\n",
    "        vec[i] = 1 - 2*i + i**2 \n",
    "        \n",
    "    return vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como la función es definida por medio de `cpdef` se puede acceder a ella desde Python. Procedemos a calcular su tiempo de ejecución promedio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit vec_func(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se compara con la misma operación pero vectorizada en Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def python_vec(d):\n",
    "    h = np.arange(d, dtype = 'double')\n",
    "    return h**2 -  2*h + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit python_vec(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo anterior demuestra que el manejo de arreglos numpy directamente desde Cython ofrece un mayor rendimiento.\n",
    "No obstante, existe una mejor manera de vectorizar el código de Python y obtener rendimeintos similares a los de Cython.\n",
    "\n",
    "**Ejercicios**\n",
    "\n",
    "1. Observe que la relación `vec[i] = 1 - 2*i + i**2` puede resumirse en `h**2` para cierto objeto NumPy `h`. Utilice este observación para modificar el código de la función `python_vec`. Compare el tiempo de ejecución de su función con la implementación de Cython. *Hint* Su implementación será un poco más lenta que `vec_func` pero más rápida que `python_vec` (x4 aproximadamente) pero tendrá la ventaja de ser mucho más sencilla que  `vec_func`.\n",
    "\n",
    "2. Genere una versión en Cython de su función vectorizada. Se espera que esta función sea más lenta que la versión de Python. ¿A qué se debe esto?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las funcionalidades que ofrece el módulo de NumPy de Cython son más bien acotadas y su notación reduce la legibilidad del código. Sumado a lo anterior, es posible que no se tengan mayores ganancias con respecto al uso de *broadcasting*, por esto motivos, se recomienda su uso sólo en circunstancias especificas que requieran un manejo de memoria especial. En casos más generales, se recomienda el uso de **memoryviews** estáticas.\n",
    "\n",
    "Una vista de memoria,**memoryview** estática o *typed memoryview* es un objeto similar a los arreglos de *C* y NumPy pues operan en zonas de memoria contigua. Este tipo de objeto, mantiene una referencia a zonas especificas de memoria pudiendo leer y modificar sus contenidos. Se puede definir una vista de memoria para objetos multidimensionales (arreglos de arreglos de arreglos ...) por medio de la sintaxis:\n",
    "\n",
    "```cython\n",
    "cdef dtype[:,:,:] var\n",
    "```\n",
    "\n",
    "Donde `dtype` es el tipo de dato a contener, `[:,:,:]` hace referencia a la cantidad de dimensiones (en este caso 3) y `var` es el nombre la variable asociada.\n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "Se genera un arreglo de NumPy y se almacena en una vista de memoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "import numpy as np\n",
    "\n",
    "cdef int[:] vec\n",
    "\n",
    "np_vec = np.zeros(100, dtype = 'int32')\n",
    "vec = np_vec\n",
    "\n",
    "print('Acceso :',vec[0])\n",
    "vec[0] = 1\n",
    "\n",
    "print('Modificacion :', np_vec[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con lo anterior, se tiene que `vec` puede acceder y modificar la información de `np_vec`, sin embargo es sólo una *vista* o *puntero* si se desea a su información contenida. Las vistas de memoria operan por tanto de la misma manera que un *slice* de NumPy en Python (recordar mutabilidad de los arreglos de NumPy) y de hecho heredan su notación de acceso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "import numpy as np\n",
    "\n",
    "cdef int[:] a\n",
    "a = np.arange(1,10, dtype = 'int32') + 1\n",
    "\n",
    "# Se accede a los elementos pares de a\n",
    "print('Slices de a: \\n ')\n",
    "\n",
    "cdef int i\n",
    "for i in a[::2]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio**\n",
    "\n",
    "1. Es posible copiar vistas de memoria por medio de una asignación simple en Cython. Defina dos vistas de memoria, `a` de dimensión 2 y `b` de dimensión 1. Asigne un arreglos de NumPy a las vistas `a` y `b`. Finalmente reemplace una dimensión de `a` con el valor de `b`. ¿Afecta este procedimiento a los arreglos de NumPy originales?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cython con Jupyer Notebook y Perfilamiento \n",
    "\n",
    "La optimización de código Cython requiere de comprobaciones exhaustivas, jupyter facilita tal análisis por medio del comando mágico `%%cython`, este comando toma opciones de linea como `-a`, con la cual es posible generar código de Cython anotado.\n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "Se produce una rutina de Cython anotada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython -a \n",
    "import numpy as np\n",
    "cimport numpy as np_c\n",
    "\n",
    "cdef double mean(double x, double y):\n",
    "    return (x+y)/2\n",
    "\n",
    "cdef double geo_mean(double x, double y):\n",
    "    return pow(x*y,0.5)\n",
    "\n",
    "cpdef double bench_p(int d):\n",
    "    \n",
    "    cdef  double[:,:] a\n",
    "    cdef double res \n",
    "    \n",
    "    a = np.random.rand(d, 2)\n",
    "    res = sum([mean(pair[0],pair[1])-geo_mean(pair[0],pair[1]) for pair in a])\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El código anterior genera una vista HTML del código original, donde las lineas amarallias indican el grado de interacción con Python, mientras más claro el nivel de color, menos interacción se tiene con Python y por tanto se tiene mayor velocidad. El extremo es un código sin lineas amarillas, esto corresponde a un código de *C*. \n",
    "\n",
    "A modo de ejemplo se estudian las lineas amarillas 7 y 8:\n",
    "\n",
    "```cython\n",
    "cdef double geo_mean(double x, double y):\n",
    "    return pow(x*y,0.5)\n",
    "```\n",
    "En este caso, Cython nos indica iteracción con Python, esta ocurre pues se hace uso de la función `pow` nativa de Python. Se puede hacer el código más eficiente al reemplazar `pow` por su equivalente de *C*, esto se logra por medio de\n",
    "\n",
    "```cython\n",
    "from libc.math cimport pow\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython -a \n",
    "import numpy as np\n",
    "cimport numpy as np_c\n",
    "\n",
    "from libc.math cimport pow\n",
    "        \n",
    "cdef double mean(double x, double y):\n",
    "    return (x+y)/2\n",
    "\n",
    "cdef double geo_mean(double x, double y):\n",
    "    return pow(x*y,0.5)\n",
    "\n",
    "cpdef double bench_c(int d):\n",
    "    \n",
    "    cdef  double[:,:] a\n",
    "    cdef double res \n",
    "    \n",
    "    a = np.random.rand(d, 2)\n",
    "    res = sum([mean(pair[0],pair[1])-geo_mean(pair[0],pair[1]) for pair in a])\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con la adición anterior, vemos que se pierden las lineas amarillas asociadas a `geo_mean`. Se hace una comparación entre ambas implementaciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -r 5 bench_p(10000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -r 5 bench_c(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que en general se gana un poco de eficiencia. A continuación se procede a cambiar las lineas 17 y 18:\n",
    "\n",
    "```cython\n",
    "a = np.random.rand(d, 2)\n",
    "res = sum([mean(pair[0],pair[1])-geo_mean(pair[0],pair[1]) for pair in a])\n",
    "```\n",
    "\n",
    "En el caso de la linea 17, generamos el arreglo aleatorio por medio de \n",
    "\n",
    "```cython    \n",
    "cdef int i;\n",
    "for i from 0 <= i < d by 1:\n",
    "    a[i][0] = rand()\n",
    "    a[i][1] = rand()\n",
    "```\n",
    "\n",
    "Donde `rand`es la función generadora de números aleatorios de *C*, esta se importa por medio de:\n",
    "\n",
    "```cython\n",
    "from libc.stdlib cimport rand\n",
    "```\n",
    "Se define además la variable global `d` por medio de `DEF d  = 10000` y se solicita el espacio necesario para el arreglo `a` utilizando tal variable:\n",
    "\n",
    "```cython\n",
    " cdef double a[d][2]\n",
    "```\n",
    "\n",
    "Vale destacar que se utiliza la notación *Pyrex* de ciclo for `for i from 0 <= i < d by 1:` que permite escribir ciclos `for` de Cython como código nativo de *C*. Finalmente se reemplaza la linea 18 por su correspondiente de *C* y se fusiona con el llenado de valores de `a` por medio de:\n",
    "\n",
    "```cython\n",
    "\n",
    "    cdef int i;\n",
    "    cdef double res = 0\n",
    "  \n",
    "    for i from 0 <= i < d by 1:\n",
    "        a[i][0] = rand()\n",
    "        a[i][1] = rand()\n",
    "        res = res + mean(a[i][0],a[i][1]) - geo_mean(a[i][0],a[i][1])\n",
    "```\n",
    "\n",
    "El código final tiene la siguiente forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython -a \n",
    "DEF d  = 10000\n",
    "\n",
    "from libc.math cimport pow\n",
    "from libc.stdlib cimport rand\n",
    "        \n",
    "cdef inline double mean(double x, double y):\n",
    "    return (x+y)/2\n",
    "\n",
    "cdef inline double geo_mean(double x, double y):\n",
    "    return pow(x*y,0.5)\n",
    "\n",
    "cdef double bench_cc():\n",
    "    \n",
    "    cdef double a[d][2]\n",
    "\n",
    "    cdef int i;\n",
    "    cdef double res = 0\n",
    "  \n",
    "    for i from 0 <= i < d by 1:\n",
    "        a[i][0] = rand()\n",
    "        a[i][1] = rand()\n",
    "        res = res + mean(a[i][0],a[i][1]) - geo_mean(a[i][0],a[i][1])\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acá se tiene que la única parte que interactua con Python es la defición `cpdef` que como sabemos, genera un ejecutable de la función en el ambiente de Python, medimos el tiempo de ejecución:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -r 5 bench_cc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que se reduce aproximadamente a la mitad con respecto a las implementaciones anteriores. \n",
    "\n",
    "**Ejercicio**\n",
    "\n",
    "1. En la definiciones de `mean` y `geo_mean` se utiliza el código `inline`. Investigue el significado de esta orden. *Hint*: la documentación de *C++* puede ser utilidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para perfilar funciones de Cython en jupyter, se puede hacer uso de `%lprun`, sin embargo, para que esto funcione es necesario alterar las directivas de Cython por medio de los comentarios \n",
    "\n",
    "```cpython\n",
    "# cython: binding=True\n",
    "# cython: linetrace=True\n",
    "```\n",
    "Además de agregar la directiva de compilación `-f -c=-DCYTHON_TRACE=1`. Sumado a lo anterior, la función de referencia (función de benchmark) debe estar declara en Python usando `def`. Se ejecuta el código necesario para perfilar la función  `bench_cp`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython -f -c=-DCYTHON_TRACE=1\n",
    "# cython: binding=True\n",
    "# cython: linetrace=True\n",
    "DEF d  = 10000\n",
    "\n",
    "from libc.math cimport pow\n",
    "from libc.stdlib cimport rand\n",
    "        \n",
    "cdef inline double mean(double x, double y):\n",
    "    return (x+y)/2\n",
    "\n",
    "cdef inline double geo_mean(double x, double y):\n",
    "    return pow(x*y,0.5)\n",
    "\n",
    "def bench_cp():\n",
    "    \n",
    "    cdef double a[d][2]\n",
    "\n",
    "    cdef int i;\n",
    "    cdef double res = 0\n",
    "  \n",
    "    for i from 0 <= i < d by 1:\n",
    "        a[i][0] = rand()\n",
    "        a[i][1] = rand()\n",
    "        res = res + mean(a[i][0],a[i][1]) - geo_mean(a[i][0],a[i][1])\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente se perfila usando `%lprun`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -f bench_cp bench_cp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiladores\n",
    "\n",
    "Cython permite ganar eficiencia por medio de la traducción y compilación de código Python. Sin embargo, la idea de compilar código de Python no es exlusiva de esta iniciativa. \n",
    "\n",
    "Un proyecto interesante la librería **Numba**, la cual en vez de traducir código Python a *C*, analiza y compila funciones de Python directamente. Compiladores como Numba, diseñados para compilar código en ejecución (y no previo a la ejecución) se denomina compiladores **JIT** (just in time). \n",
    "\n",
    "Numba permite compilar funciones individuales de Python usado una *máquina virtual de bajo nivel* o LLVM por sus siglas en inglés. LLVM es un conjunto de herramientas pensadas para escribir compiladores y no depende del lenguaje utilizado para programar. \n",
    "\n",
    "Por medio de LLVM Numba inspecciona funciones de Python y las compila utilizando una capa de representación intermedia similar a código *assembly*. La potencia de esta inspección radica en la inferencia de tipos de datos generando una versiones compiladas con tipos de datos estáticos.\n",
    "\n",
    "Numba se basa principalmente en el decorador `@jit` con el cual se definen las funciones a compilar.\n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "Se genera una función simple y se compila usando el decorador `@jit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x):\n",
    "    res = 0\n",
    "    n = len(x)\n",
    "    \n",
    "    for i in range(1,n):\n",
    "        res += x[i-1]*(x[i]-1)\n",
    "        \n",
    "    res /= n**3\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se prueba mide el tiempo de ejecución para arreglo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(1e5)\n",
    "x = np.arange(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit func(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se decora la función para ser compilada "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit\n",
    "\n",
    "@jit\n",
    "def func_n1(x):\n",
    "    res = 0\n",
    "    n = len(x)\n",
    "    \n",
    "    for i in range(1,n):\n",
    "        res += x[i-1]*(x[i]-1)\n",
    "        \n",
    "    res /= n**3\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "se ejecuta la misma prueba de rendimiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit func_n1(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con lo que se observa un aumento substancial en la eficiencia. \n",
    "\n",
    "Por otra parte, se compara con la versión vectorizada en NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit np.sum(x[:(n-1)]*(x[1:] -1))/n**3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "con lo que se aprecia un aumento en rendimiento aún comparando con el código vectorizado de NumPy. En este caso, el aumento en el rendimiento viene dado por el manejo de memoria *inplace* que posee la función `func_n1` en comparación con el posicionamiento de un arreglo (temporal) extra de NumPy según la operación `x[:(n-1)]*(x[1:] -1)`. Por lo anterior, no se espera una mejora substancial al vectorizar `func_n1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def func_n2(x):\n",
    "    return np.sum(x[:(n-1)]*(x[1:] -1))/n**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit func_n2(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo anterior confirma que no se aumenta el rendimiento de `func_n1` al vectorizar su comportamiento dado el manejo de memoria que requiere la operación vectorizada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio**\n",
    "\n",
    "1. Observe que `func_n1` puede operar sobre arreglos de Numpy o listas contenedoras números. Utilice `func_n1` sobre una lista de numeros y compare el rendimiento con una suma sobre una compresión de lista de Python. ¿Qué método es más rápido?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numba permite indicar tipos de datos por medio de la firma o *signature* sobre la función decorada. La sintaxis es del tipo:\n",
    "\n",
    "```python\n",
    "@jit(output_dtype(input_dtype_1,..., input_dtype_n))\n",
    "```\n",
    "donde `output_dtype` es el tipo de dato esperado como respuesta de la función e `input_dtype_1`,...,`input_dtype_n` son los tipos de datos esperados como argumentos y proporcionados por Numba.\n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "Se observan la firmas de `func_n1` por medio del atributo `.signatures`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_n1.signatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La firma anterior concuerda con el tipo de dato de `x`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se opera sobre `func_n1` utilizando un nuevo tipo de dato y se estudian nuevamente sus firmas de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = np.random.rand(n).astype(dtype = 'float32')\n",
    "func_n1(xx)\n",
    "func_n1.signatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para agregar firmas para arreglos se utiliza la notación de *memoryview*. Se agrega una firma especifica a `func_n1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import float32\n",
    "\n",
    "@jit(float32(float32[:]))\n",
    "def func_n3(x):\n",
    "    res = 0\n",
    "    n = len(x)\n",
    "    \n",
    "    for i in range(1,n):\n",
    "        res += x[i-1]*(x[i]-1)\n",
    "        \n",
    "    res /= n**3\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al especificar los tipos de datos operados, no se pueden entregar tipos de datos distintos pues se genera una excepción `TypeError  `. Por esto, se espera que `func_n3` funcione correctamente sobre `xx` pero no sobre `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    print('func_n3(xx):',func_n3(xx))\n",
    "\n",
    "except TypeError:\n",
    "\n",
    "    print('El tipo de dato de x es', xx.dtype)\n",
    "    print('Se espera como input float32') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    print('func_n3(x):',func_n3(x))\n",
    "\n",
    "except TypeError:\n",
    "    print('El tipo de dato de x es', x.dtype)\n",
    "    print('Se espera como input float32') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicios**\n",
    "\n",
    "1. Numba permite especificar firmas de datos utilizando strings. Implemente una función de Python que retorne datos tipo `int32` y reciba como argumentos arreglos de tipo `float64`.\n",
    "\n",
    "2. Implemente una función de Python y especifique por medio de Numba la firma para el input (sólo para input, no para el output).\n",
    "\n",
    "3. Declare una función de Python y declare múltiples firmas para esta utilizando listas y formato string.\n",
    "\n",
    "**Obs**: Se espera que especifique las firmas anteriores dentro de un decorador `@jit`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se observó con Cython, es posible mejorar de manera substancial el rendimiento de ejecución en funciones compiladas por medio de la especificación de tipos de dato estáticos. Si bien el decorador `@jit` infiere de manera eficiente los tipos de datos (como se observa en `func_n1`) , existen casos donde este tipo de inferencia no es tan sencillo. \n",
    "\n",
    "Cuando Numba no es capaz de inferir los tipos de datos en una función de Python, se utiliza el interprete de Python en lo que se llama **Object mode** que por definición es menos eficiente que utilizar tipos de datos estáticos (inferidos o proporcionados) que se denomina **Native mode**. \n",
    "\n",
    "Para comprender la inferencia de tipos de datos hecha por Numba, se puede utilizar la función `inspect_types`. Esta entrega bloques formateados con información relevante sobre e manejo de variables, en el caso de la función `func_1` se tiene:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_n1.inspect_types()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí se puede observar el proceso de inferencia asociado a la linea `res = 0`:\n",
    "```\n",
    "# --- LINE 14 --- \n",
    "    # label 0\n",
    "    #   x = arg(0, name=x)  :: array(float32, 1d, C)\n",
    "    #   $const2.0 = const(int, 0)  :: Literal[int](0)\n",
    "    #   res = $const2.0  :: Literal[int](0)\n",
    "    #   del $const2.0\n",
    "    \n",
    "    res = 0\n",
    "```\n",
    "En este caso se observa que la variable `res` es asociada a la constante ```const2.0 = const(int, 0)  :: Literal[int](0)``` que es inferida como una variable tipo `int`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio**\n",
    "\n",
    "La inferencia de tipos es una gran fortaleza de Numba, sin embargo, cuando esta falla se entra en *object mode* y se procede a calcular utilizando el interprete de Python. Esto termina generando un código más lento que el original.\n",
    "\n",
    "1. Las listas anidadas generan problemas para determinar tipos de dato por parte de Numba. Compruebe esta afirmación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paralelismo\n",
    "\n",
    "El paralelismo se basa en el uso de múltiples unidades de computo de manera simulánea, con el el fin de mejorar la eficiencia en rutinas de código. La idea principal consite en enfrentar un problema de programación, dividiendolo en subunidades independientes y utilizar los núcleos disponibles de la máquina para resolver tales subunidades en paralelo.\n",
    "\n",
    "Por lo general se necesitan téctinas de paralelismo en problemas de gran escala. Un problema donde todas sus subunidades son independientes entre si, se denomina **perfectamente paralelo**. Las operaciones elemento por elemento sobre arreglos poseen esta propiedad. \n",
    "\n",
    "Por lo general, las subunidades de un programa no son completamente independientes y necesitan compartir información, en estos casos,se debe tener en cuenta que la comunicación entre subunidades y los datos compartidos **quitan eficiencia** al problema que se resuelve, pues se incurre en *costos de comunicación*. La comunicación entre procesos es inherentemente costosa y puede llevar fallas de correctitud. Por ejemplo, al manejar de manera simultanea un arreglo, es posible que se corrompa su bloque de memoria asociado, por lo demás, si dicho bloque de memoria se encuentra en disco, su costo de acceso es bastante alto.\n",
    "\n",
    "Por lo general, se enfrenta el problema de costo de comunicación y correctud del manejo de memoria por medio de sistemas que se comunican por medio de **memoria compartida** y **memoria distribuida**. En el caso de memoria compartida, las subunidades involucradas en el programa tienen acceso a un espacio común de memoria, este por lo general es de acceso rápido, si bien esto solventa el problema de velocidad de comunicación, el problema de correctitud sigue latente, por lo que se hace necesario utilizar técnicas para sincronizar los procesos sobre esta memoria. \n",
    "\n",
    "Por otra parte, el concepto de memoria distribuida concibe cada subunidad como un proceso completamente separado del resto con su propio espacio de memoria asociado. En este caso, la comunicación entre procesos se debe manejar de manera explicita y es más costosa que en el caso de memoria compartida, sin embargo, se reduce el riesgo de generar errores en el manejo de memoria. Este tipo de paralelismo se observa en *clusters* que consisten máquinas conformadas por múltiples unidades de computo independientes.\n",
    "\n",
    "La manera usual en la que se implementan procesos de memoria compartida es por medio de **threads** o *hilos*. Estos consisten en subtareas originadas de un proceso en particular y que comparten recursos. \n",
    "\n",
    "Python puede manejar threads pero dado el diseño de su interprete, por defecto, se puede ejecutar solo una tarea a la vez, esto se conoce como **GIL** (Global Interpreter Lock). GIL provoca que cada vez que un hilo ejecute una orden de Python, se genere un bloqueo que solo será liberado una vez la ejecución del hilo termine. Esto hace que los hilos solo puedan ser ejecutados de manera secuencial.\n",
    "\n",
    "Aunque GIL evita la ejecución paralela de las intrucciones de Python, es posible utilizar hilos mediante algunas librerías. La principal es `multiprocessing`\n",
    "\n",
    "Multiprocessing ofrece una interfaz sencilla que incluye múltiples herramientas para manejar sincronozación y ejecución de tareas. Es posible importar esta librería de manera estándar. \n",
    "\n",
    "```python\n",
    "import multiprocessing\n",
    "```\n",
    "\n",
    "Es posible crear procesos independientes por medio la clase `Process`, para ello basta extender el método `__init__` para inicializar los datos a procesar y generar el método `run` sobre el cual se ejecuta el proceso.\n",
    "\n",
    "**Ejemplo**\n",
    " \n",
    "Se genera un proceso independiente utilizando la clase `Process`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process\n",
    "import time\n",
    "\n",
    "class Proceso_ind(Process):\n",
    "    \n",
    "    def __init__(self, num):\n",
    "        super().__init__()\n",
    "        self.num = num\n",
    "    \n",
    "    def run(self):\n",
    "        print('Proceso numero:', self.num)\n",
    "        time.sleep(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para utilizar el proceso se instancia un objeto de la clase `Proceso_ind` y se llama el método `.start()` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc = Proceso_ind(5)\n",
    "proc.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obs**:En el ejemplo anterior, no fue necesario utilizar el metodo anulado `.run()`, este es llamado por `.start()` de manera interna."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las instrucciones luego de `proc.start()` y en general, luego de `Process.start` son ejecutadas de manera inmediata sin esperar a que el proceso finalice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc = Proceso_ind(5)\n",
    "proc.start()\n",
    "print('proceso siguiente')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se comprueba que la ejecución de la orden siguiente es inmediata pues se debía esperar tres segundos dados por la orden `  time.sleep(3)`. En el caso en que se requiera esperar la finalización de un conjunto de tareas paralelas para luego recopilar resultados, es posible utilizar el método `.join()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc = Proceso_ind(5)\n",
    "proc.start()\n",
    "proc.join()\n",
    "print('proceso siguiente')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con la construcción actual, es posible levantar tantos procesos como se requiera, en esta caso se levantan 3 procesos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se definen los 3 procesos\n",
    "proc = (Proceso_ind(1), Proceso_ind(2), Proceso_ind(3))\n",
    "\n",
    "# Se mide el tiempo de ejecucion\n",
    "start = time.time()\n",
    "\n",
    "[*map(lambda p: p.start(), proc)]\n",
    "[p.join() for p in proc]\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "\n",
    "print('Tiempo de ejecución: ', end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "estos tres procesos corren de manera paralela, pues su tiempo de ejecución total es aproximado al tiempo de ejecución individual. Es necesario comprender que el orden de ejecución de procesos paralelos no es necesariamente ordenando y predecible pues depende de cómo el sistema operativo asigne los recursos. \n",
    "\n",
    "El módulo `multiprocessing` ofrece la clase `Pool`, esta permite manejar de manera sencilla un conjunto de procesos paralelos. Esta clase genera un conjunto de procesos llamados **workers** a los cuales se les asignan tareas por medio de los métodos `.apply()`, `.apply_async()`, `map` o `map_async`. \n",
    "\n",
    "El método `Pool.map()` actua de manera análoga la función nativa `map` de Python. Como resultado entrega una lista con los resultados, donde cada componente es el resultado de un worker de la clas.\n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "Para utilizar el método `.map` de la clase `Pool` se inicializa la clase, es posible hacerlo sin entregar un número de procesos asociados. Se genera también la función a paralelizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "def func(x):\n",
    "    return x**2 - 1\n",
    "\n",
    "p = Pool(3) #tambien funciona Pool()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se comprueban los resultados y se cierra el conjunto de procesos por medio de `.close()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = [2,4,6,8,10,12]\n",
    "out = p.map(func, var)\n",
    "p.close()\n",
    "\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método `.map_async()` es análogo al método `.map()` con la salvedad de que retorna un objeto tipo `AsyncResult`. Esto significa que el resultado de ejecutar `.map_async()` se obtiene de manera inmediata, pudiendo continuar con las demás ordenes que proceden pero seguirá calculandose como proceso de fondo. para acceder a los resultados asociados al objeto `AsyncResult` se utiliza el método `.get()`.\n",
    "\n",
    "Utilizamos el método de mapeo asincrónico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Pool(3) #tambien funciona Pool()\n",
    "\n",
    "var = [2,4,6,8,10,12]\n",
    "out = p.map_async(func, var)\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accedemos a sus resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(out.get())\n",
    "p.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicios**\n",
    "\n",
    "Los métodos `.apply()` y `apply_async()` son similares a `.map()` y `.map_async()`\n",
    "\n",
    "1. ¿En qué se diferencian?\n",
    "2. Programe una rutina que haga uso de `.apply()` y `apply_async()`. \n",
    "\n",
    "3. ¿Cómo se relaciona la clase `Pool` y los métodos de aplicación (`.map()`, `.apply()`, ...) con las funciones de Cython ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El comportamiento predeterminado de `multiprocessing` es generar procesos con memoria independiente, sin embargo, permite definir ciertas variables en memoria compartida. Para definir una variabl en memoria compartida se utiliza la clase `Value`, a esta clase se le entrega un tipo de dato que puede ser `i` para entero, `f` para flotante, `d` para doble precisión entre otros. \n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "Se define una variable en memoria compartida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Value\n",
    "\n",
    "comp_var = Value('d')\n",
    "comp_var = 55"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al utilizar variables en memoria compartida se deben tener en cuenta los procesos que acceden a ella, manejando la *concurrencia*, es decir, si los procesos pueden acceder a dichas variables de manera simultanea u ordenada. Por lo general en la actualización de valores unidimensionales se debe tener en cuenta la concurrencia bloqueando el acceso simultaneo. En arreglos se puede permitir tal manipulación siempre que los computos sean independientes. \n",
    "\n",
    "Para bloquear el acceso a una variable compartida se hace uso de la clase `Lock`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Lock\n",
    "lock = Lock()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se genera una rutina que accede a una variable de memoria compartida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process, Value\n",
    "\n",
    "class Process_shared(Process):\n",
    "    \n",
    "    def __init__(self, var, n = 10000):\n",
    "        super().__init__()\n",
    "        self.var = var\n",
    "        self.n = n\n",
    "\n",
    "    def run(self):\n",
    "        for i in range(self.n):\n",
    "            self.var.value += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El proceso asociado toma un valor y le añade 1 hasta `n = 10000` veces por proceso. Se crea el valor inicial y se inicializan 3 procesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    var = Value('i')\n",
    "    var.value = 0\n",
    "\n",
    "    procs = [Process_shared(var) for i in range(3)]\n",
    "    \n",
    "    [p.start() for p in procs]\n",
    "    [p.join() for p in procs]\n",
    "    \n",
    "    print(var.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se prueba el resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede ver, el resultado no es necesariamente 30.000, esto se debe al acceso simultaneo y aleatorio de los procesos a `var`, para solucionar este problema se hace uso de `lock`, para ello se redefine la clase `Process_shared` observando que lock es un *context manager*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Process_shared_lock(Process):\n",
    "    \n",
    "    def __init__(self, var, n = 10000):\n",
    "        super().__init__()\n",
    "        self.var = var\n",
    "        self.n = n\n",
    "\n",
    "    def run(self):\n",
    "        for i in range(self.n):\n",
    "            with lock:\n",
    "                self.var.value += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se redefine la prueba asociada y se ejecuta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    var = Value('i')\n",
    "    var.value = 0\n",
    "\n",
    "    procs = [Process_shared_lock(var) for i in range(3)]\n",
    "    \n",
    "    [p.start() for p in procs]\n",
    "    [p.join() for p in procs]\n",
    "    \n",
    "    print(var.value)\n",
    "    \n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con lo cual se obtiene el resultado buscado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procesamiento Distribuido\n",
    "\n",
    "El procesamiento distribuido hace referencia a la ejecución de tareas utilizando múltiples máquinas. Por lo general se refiere al trabajo con clusters de procesamiento y suele llevarse a cabo por medio de herramientas como MPI. \n",
    "\n",
    "En Python existen diversas librerías que permiten computación distribuida. En esta última sección estudiaremos una de ellas: Dask.\n",
    "\n",
    "Dask permite escalar objetos y procedimientos de Python ya sea en un computador personal o un cluster de manera sencilla. Provee de funcionalidades para tratar, por medio de procesamiento multi-core, con datsets masivos que por lo general no caben en memoria. \n",
    "\n",
    "Dask proporciona planificadores de bajo nivel, cuya función es sincronizar tareas entre múltiples procesos o máquinas, análogo a la librería `multiprocessing` recientemente estudiada. \n",
    "\n",
    "Finalmente, Dask se instala de manera estándar por medio de `pip` o `conda` y se accede a sus objetos y funciones de la manera usual. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paralelización de código con Dask\n",
    "\n",
    "Una manera sencilla de utilizar Dask es comenzando por paralelizar rutinas de código, esto se puede hacer usando el decorador `delayed`.\n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "Se definen dos funciones y se paralelizan usando `delayed`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask import delayed\n",
    "\n",
    "import time\n",
    "from time import sleep\n",
    "\n",
    "def func_1(x):\n",
    "    sleep(1)\n",
    "    return x**2 + 1\n",
    "\n",
    "def func_2(x, y):\n",
    "    sleep(1)\n",
    "    return x**2 + y**2 - 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se mide le tiempo de ejecución de las funciones implementadas, para ello se implementa un context manager:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Timer: \n",
    "    '''Context manager Timer'''\n",
    "    def __enter__(self):\n",
    "        self.inicio = time.time()\n",
    "    \n",
    "    def __exit__(self,*args,**kwargs):\n",
    "        print('Tiempo de ejecución:', time.time() - self.inicio, 'segs') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer() as t:\n",
    "    x = func_1(5)\n",
    "    y = func_1(55)\n",
    "    z = func_2(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "como es de esperar, se tiene un tiempo de ejecución similar a los 3 segundos esperados. Para paralelizar las funciones anteriores se hace uso del decorador `@delayed`, si recordamos que la notación:\n",
    "\n",
    "```python\n",
    "@decorator\n",
    "def func(*args,**kwargs):\n",
    "    res = do_stuff(*args,**kwargs)\n",
    "    return res\n",
    "```\n",
    "\n",
    "Es de hecho equivalente a:\n",
    "\n",
    "```python\n",
    "func = decorator(func)\n",
    "```\n",
    "\n",
    "entonces se puede hacer una decoración *inline* de las funciones antes construidas, luego para parelelizar el código anterior, se hace uso del siguiente código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer() as t:\n",
    "    x = delayed(func_1)(5)\n",
    "    y = delayed(func_1)(55)\n",
    "    z = delayed(func_2)(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Donde se ve una mejora substancial en el tiempo de ejecución. El código de benchamark generado debería ejecutarse en aproximadamente 2 segundos, esto pues las operaciones que definen a `x` y a `y` son independientes y cada una toma un segundo, por lo que hacerlas de manera simultanea debe tomar alrededor de 1 segundo, finalmente, la sección que define a `z` toma 1 segundo y debe esperar el resultado de `x` e `y`, con lo que se tienen 2 segundos en total. Sin embargo, el código anterior se ejecuta en menos de un segundo, para entender este comportamiento haremos un print de pantalla con los resultados de la operación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n ---> Version secuencial')\n",
    "with Timer() as t:\n",
    "    x = func_1(5)\n",
    "    y = func_1(55)\n",
    "    z = func_2(x, y)\n",
    "    print('z =',z)\n",
    "    \n",
    "\n",
    "print('\\n ---> Version paralela')\n",
    "with Timer() as t:\n",
    "    x = delayed(func_1)(5)\n",
    "    y = delayed(func_1)(55)\n",
    "    z = delayed(func_2)(x, y)\n",
    "    print('z =',z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esto se observa que la versión secuencial se comporta como es debido, pero en la versión paralela lo que se obtiene es un objeto tipo `Delayed`. Lo que ocurre entonces es que cuando se opera con funciones `delayed` se procede a calcular de manera asincrónica, por lo tanto, si se desea obtener el resultado de `z` para continuar con nuevas secciones del código, es necesario recolectar los resultados antes de continuar, similar al método `.join()` de la librería `multiprocessing`, esto se hace por medio del método `compute`. Comparamos finalmente los resultados al incluir `compute` dentro del código paralelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n ---> Version secuencial')\n",
    "with Timer() as t:\n",
    "    x = func_1(5)\n",
    "    y = func_1(55)\n",
    "    z = func_2(x, y)\n",
    "    print('z =',z)\n",
    "    \n",
    "\n",
    "print('\\n ---> Version paralela')\n",
    "with Timer() as t:\n",
    "    x = delayed(func_1)(5)\n",
    "    y = delayed(func_1)(55)\n",
    "    z = delayed(func_2)(x, y)\n",
    "    print('z =',z.compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con lo que vemos que se confirma la predicción en cuanto al tiempo de ejecución. \n",
    "\n",
    "Los objetos tipo de `Delayed` se evaluan de manera *lazy*, esto quiere decir que esperan a que todos los resultados intermedios estén realizados para evaluar sus operaciones. Al construir funciones `delayed` Dask genera un grafo acíclico dirigido (DAG) con el cual almacena las relaciones entre objetos `Delayed` intermedios, para visualizar las relaciones de objetos intermedios, asociados a un objeto `Delayed` se hace uso del método `.visualize()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = delayed(func_1)(5)\n",
    "y = delayed(func_1)(55)\n",
    "z = delayed(func_2)(x, y)\n",
    "\n",
    "print('z =',z.compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio** \n",
    "\n",
    "El método de paralelización ofrecido por `delayed` puede ser de especial ayuda al momento de trabajar con ciclos, donde los resultados son recolectados en un arreglo y luego reducidos por alguna operación. \n",
    "\n",
    "1. Defina una función `f` que reciba un input numérico `x` y entrege como resultado una transformación de este. \n",
    "\n",
    "2. Por medio de ciclo `for` transforme los elementos de un arreglo de dimensión `n`, en cada iteración, guarde los resultados de la transformación en una componente de un arreglo.\n",
    "\n",
    "3. Aplique una operación de reducción sobre el arreglo contenedor de resultados. (Ejemplo: el promedio de los elementos de arreglo contenedor)\n",
    "\n",
    "4. Paralelice el proceso anterior usando el decorador `delayed` donde corresponda. ¿Qué funciones fue necesario decorar? ¿Cómo implementaría esto usando `multiprocessing`?\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
